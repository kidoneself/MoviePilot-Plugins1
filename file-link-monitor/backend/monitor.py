import time
import logging
import threading
from datetime import datetime
from pathlib import Path
from typing import List
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileMovedEvent

from backend.models import LinkRecord, get_session
from backend.utils.linker import FileLinker
from backend.utils.notifier import Notifier
from backend.utils.taosync import TaoSyncClient, TaoSyncQueue

logger = logging.getLogger(__name__)


class FileMonitorHandler(FileSystemEventHandler):
    """æ–‡ä»¶ç›‘æ§å¤„ç†å™¨"""
    
    def __init__(self, source_path: str, target_configs: List[dict], 
                 exclude_patterns: List[str], db_engine, config: dict, obfuscate_enabled: bool = False,
                 template_files_path: str = None):
        self.source_path = Path(source_path)
        self.target_configs = target_configs  # [{"path": "...", "name": "..."}, ...]
        self.target_paths = [Path(t['path'] if isinstance(t, dict) else t) for t in target_configs]
        self.exclude_patterns = exclude_patterns or []
        self.db_engine = db_engine
        self.obfuscate_enabled = obfuscate_enabled
        self.linker = FileLinker(obfuscate_enabled=obfuscate_enabled, db_engine=db_engine)
        self.notifier = Notifier(config)
        self.template_files_path = Path(template_files_path) if template_files_path else None
        self.linked_dirs = set()  # è®°å½•å·²ç»é“¾æ¥è¿‡æ¨¡æ¿æ–‡ä»¶çš„ç›®å½•
        
        # åˆå§‹åŒ–TaoSyncå®¢æˆ·ç«¯å’Œé˜Ÿåˆ—
        self.taosync_queue = None
        taosync_config = config.get('taosync', {})
        if taosync_config.get('enabled'):
            # è¯»å–ä»»åŠ¡IDé…ç½®ï¼ˆæ”¯æŒåˆ—è¡¨æˆ–å•ä¸ªIDï¼‰
            job_id_config = taosync_config.get('job_id')
            if isinstance(job_id_config, list):
                # åˆ—è¡¨æ ¼å¼ï¼š[1, 2, 3]
                job_ids = job_id_config
            elif isinstance(job_id_config, (int, str)):
                # å•ä¸ªIDæˆ–é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼š"1,2,3"
                if isinstance(job_id_config, str) and ',' in job_id_config:
                    job_ids = [int(x.strip()) for x in job_id_config.split(',')]
                else:
                    job_ids = [int(job_id_config)]
            else:
                job_ids = [1]  # é»˜è®¤å€¼
            
            taosync_client = TaoSyncClient(
                url=taosync_config.get('url', ''),
                username=taosync_config.get('username', 'admin'),
                password=taosync_config.get('password', ''),
                job_ids=job_ids  # ä½¿ç”¨job_idså‚æ•°
            )
            # åˆ›å»ºé˜Ÿåˆ—ç®¡ç†å™¨ï¼Œè®¾ç½®æ£€æŸ¥é—´éš”
            check_interval = taosync_config.get('check_interval', 60)  # é»˜è®¤60ç§’
            self.taosync_queue = TaoSyncQueue(
                client=taosync_client,
                check_interval=check_interval,
                notifier=lambda msg: self.notifier.notify_info("TaoSyncé˜Ÿåˆ—", msg)
            )
            self.taosync_queue.start()
            logger.info(f"TaoSyncå·²å¯ç”¨ï¼Œä»»åŠ¡ID: {job_ids}ï¼Œé˜Ÿåˆ—æ£€æŸ¥é—´éš”: {check_interval}ç§’")
        
        # æ‰¹æ¬¡æ±‡æ€»ç›¸å…³
        self.batch_files = []  # æ‰¹æ¬¡å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
        self.last_process_time = None  # æœ€åå¤„ç†æ—¶é—´
        self.batch_timer = None  # æ±‡æ€»å®šæ—¶å™¨
        self.batch_lock = threading.Lock()  # æ‰¹æ¬¡æ•°æ®é”
        
        logger.info(f"åˆå§‹åŒ–ç›‘æ§: {source_path} -> {self.target_paths}, æ··æ·†: {obfuscate_enabled}")
    
    def on_created(self, event):
        """æ–‡ä»¶åˆ›å»ºäº‹ä»¶"""
        if event.is_directory:
            return
        
        file_path = Path(event.src_path)
        logger.info(f"æ£€æµ‹åˆ°æ–°æ–‡ä»¶: {file_path}")
        self._process_file(file_path)
    
    def on_moved(self, event):
        """æ–‡ä»¶ç§»åŠ¨äº‹ä»¶"""
        if event.is_directory:
            return
        
        file_path = Path(event.dest_path)
        logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶ç§»åŠ¨: {file_path}")
        self._process_file(file_path)
    
    def _process_file(self, file_path: Path):
        """å¤„ç†æ–‡ä»¶"""
        # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
        time.sleep(1)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file_path.exists():
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        # åªå¤„ç†åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘+å­—å¹•ï¼‰
        from backend.utils.obfuscator import FolderObfuscator
        if not FolderObfuscator.is_media_file(file_path):
            logger.debug(f"éåª’ä½“æ–‡ä»¶ï¼Œè·³è¿‡: {file_path}")
            return
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
        if self.linker.should_exclude(file_path, self.exclude_patterns):
            logger.info(f"æ–‡ä»¶è¢«æ’é™¤: {file_path}")
            return
        
        # è·å–ç›¸å¯¹è·¯å¾„
        try:
            relative_path = file_path.relative_to(self.source_path)
        except ValueError:
            logger.error(f"æ–‡ä»¶ä¸åœ¨æºç›®å½•ä¸­: {file_path}")
            return
        
        # è·å–æ–‡ä»¶å¤§å°
        try:
            file_size = file_path.stat().st_size
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {e}")
            file_size = 0
        
        # ä¸ºæ¯ä¸ªç›®æ ‡ç›®å½•åˆ›å»ºç¡¬é“¾æ¥
        session = get_session(self.db_engine)
        success_count = 0
        failed_count = 0
        last_error = None
        success_targets = []
        
        try:
            for idx, target_path in enumerate(self.target_paths):
                target_file = target_path / relative_path
                
                logger.info(f"åˆ›å»ºé“¾æ¥: {file_path} -> {target_file}")
                success, method, error, actual_target = self.linker.create_hardlink(
                    file_path, target_file, 
                    source_base=self.source_path, 
                    target_base=target_path
                )
                
                if success:
                    success_count += 1
                    # è·å–ç›®æ ‡ç›®å½•çš„è‡ªå®šä¹‰åç§°
                    target_config = self.target_configs[idx]
                    target_name = target_config.get('name', target_config.get('path', str(target_path))) if isinstance(target_config, dict) else str(target_path)
                    success_targets.append(f"{target_name}: {file_path.name}")
                    
                    # è‡ªåŠ¨é“¾æ¥æ¨¡æ¿æ–‡ä»¶åˆ°å‰§é›†æ–‡ä»¶å¤¹ï¼ˆåªé“¾æ¥ä¸€æ¬¡ï¼‰
                    if self.template_files_path and self.template_files_path.exists() and actual_target:
                        target_show_dir = actual_target.parent  # ä½¿ç”¨å®é™…åˆ›å»ºçš„æ–‡ä»¶è·¯å¾„
                        # å¦‚æœæ˜¯å­£åº¦æ–‡ä»¶å¤¹ï¼Œè·å–å‰§é›†æ ¹ç›®å½•
                        if target_show_dir.name.startswith('Season'):
                            target_show_dir = target_show_dir.parent
                        
                        # ä½¿ç”¨ç›®å½•è·¯å¾„ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œé¿å…é‡å¤é“¾æ¥
                        dir_key = str(target_show_dir)
                        if dir_key not in self.linked_dirs:
                            linked_count = self.linker.link_template_files(target_show_dir, self.template_files_path)
                            if linked_count > 0:
                                logger.info(f"âœ“ å·²é“¾æ¥ {linked_count} ä¸ªæ¨¡æ¿æ–‡ä»¶åˆ°: {target_show_dir}")
                                self.linked_dirs.add(dir_key)
                else:
                    failed_count += 1
                    last_error = error
                
                # è®°å½•åˆ°æ•°æ®åº“ï¼ˆä¿å­˜å®é™…åˆ›å»ºçš„æ··æ·†åè·¯å¾„ï¼‰
                # æŸ¥è¯¢æˆ–åˆ›å»ºè®°å½•
                record = session.query(LinkRecord).filter(
                    LinkRecord.source_file == str(file_path)
                ).first()
                
                if not record:
                    # åˆ›å»ºæ–°è®°å½•
                    from backend.utils.obfuscator import FolderObfuscator
                    original_name = FolderObfuscator.extract_show_name(file_path)
                    record = LinkRecord(
                        source_file=str(file_path),
                        original_name=original_name,
                        file_size=file_size
                    )
                    session.add(record)
                
                # æ ¹æ®target_nameåˆ¤æ–­æ˜¯å“ªä¸ªç½‘ç›˜
                target_config = self.target_configs[idx]
                target_name = target_config.get('name', '') if isinstance(target_config, dict) else ''
                
                if success and actual_target:
                    # æ ¹æ®ç½‘ç›˜åç§°æ›´æ–°å¯¹åº”å­—æ®µ
                    if 'å¤¸å…‹' in target_name or 'æµ‹è¯•1' in target_name or idx == 0:
                        record.quark_target_file = str(actual_target)
                        record.quark_synced_at = datetime.now()
                    else:
                        record.baidu_target_file = str(actual_target)
                        record.baidu_synced_at = datetime.now()
                    
                    record.updated_at = datetime.now()
            
            session.commit()
            logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name}")
            
            # æ·»åŠ åˆ°æ‰¹æ¬¡æ±‡æ€»
            if success_count > 0:
                self._add_to_batch({
                    'file_name': file_path.name,
                    'targets': success_targets,
                    'time': datetime.now()
                })
            if failed_count > 0:
                self.notifier.notify_sync_failed(file_path.name, last_error or "æœªçŸ¥é”™è¯¯")
                
        except Exception as e:
            logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            session.rollback()
        finally:
            session.close()
    
    def _add_to_batch(self, file_info: dict):
        """æ·»åŠ æ–‡ä»¶åˆ°æ‰¹æ¬¡æ±‡æ€»"""
        with self.batch_lock:
            self.batch_files.append(file_info)
            self.last_process_time = datetime.now()
            
            # é‡ç½®æ±‡æ€»å®šæ—¶å™¨
            if self.batch_timer:
                self.batch_timer.cancel()
            
            # 30ç§’åæ£€æŸ¥æ˜¯å¦å‘é€æ±‡æ€»
            self.batch_timer = threading.Timer(30.0, self._check_and_send_batch)
            self.batch_timer.daemon = True
            self.batch_timer.start()
    
    def _check_and_send_batch(self):
        """æ£€æŸ¥å¹¶å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥"""
        with self.batch_lock:
            if not self.batch_files:
                return
            
            # æ£€æŸ¥æ˜¯å¦30ç§’å†…æ— æ–°æ–‡ä»¶
            if self.last_process_time and (datetime.now() - self.last_process_time).total_seconds() >= 30:
                self._send_batch_summary()
    
    def _send_batch_summary(self):
        """å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥"""
        if not self.batch_files:
            return
        
        try:
            file_count = len(self.batch_files)
            file_names = [f['file_name'] for f in self.batch_files]
            
            # å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥
            self.notifier.notify_batch_sync_success(file_names)
            
            # è§¦å‘TaoSyncåŒæ­¥
            if self.taosync_queue:
                logger.info(f"æ‰¹æ¬¡å®Œæˆï¼Œè§¦å‘TaoSyncåŒæ­¥ä»»åŠ¡ï¼ˆå…±{file_count}ä¸ªæ–‡ä»¶ï¼‰")
                success, reason = self.taosync_queue.trigger_now(file_count=file_count)
                if success:
                    self.notifier.notify_taosync_triggered_batch(file_count)
                elif reason == "queued":
                    logger.info(f"TaoSyncä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—ï¼Œç­‰å¾…æ‰§è¡Œï¼ˆæ–‡ä»¶æ•°: {file_count}ï¼‰")
                else:
                    logger.error(f"TaoSyncè§¦å‘å¤±è´¥: {reason}")
            
            logger.info(f"æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥å·²å‘é€ï¼šå…±å¤„ç† {file_count} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥å¤±è´¥: {e}")
        finally:
            # æ¸…ç©ºæ‰¹æ¬¡åˆ—è¡¨
            self.batch_files = []
            self.last_process_time = None


class MonitorService:
    """ç›‘æ§æœåŠ¡"""
    
    def __init__(self, config: dict, db_engine):
        self.config = config
        self.db_engine = db_engine
        self.observer = None
        self.handlers = []
        self.notifier = Notifier(config)
    
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        monitors = self.config.get('monitors', [])
        
        if not monitors:
            logger.warning("æœªé…ç½®ç›‘æ§ç›®å½•")
            return
        
        self.observer = Observer()
        
        for monitor in monitors:
            if not monitor.get('enabled', True):
                logger.info(f"ç›‘æ§å·²ç¦ç”¨: {monitor['source']}")
                continue
            
            source = monitor['source']
            targets_config = monitor['targets']
            exclude = monitor.get('exclude_patterns', [])
            obfuscate = monitor.get('obfuscate_enabled', False)
            template_path = monitor.get('template_files_path')
            
            # æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨
            if not Path(source).exists():
                logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {source}")
                continue
            
            # åˆ›å»ºç›‘æ§å¤„ç†å™¨ï¼ˆä¼ é€’å®Œæ•´çš„targeté…ç½®ï¼‰
            handler = FileMonitorHandler(source, targets_config, exclude, self.db_engine, self.config, obfuscate, template_path)
            self.handlers.append(handler)
            
            # å¯åŠ¨ç›‘æ§
            self.observer.schedule(handler, source, recursive=True)
            logger.info(f"âœ… å¯åŠ¨ç›‘æ§: {source}")
        
        self.observer.start()
        logger.info("ç›‘æ§æœåŠ¡å·²å¯åŠ¨")
    
    def sync_all(self):
        """å…¨é‡åŒæ­¥æ‰€æœ‰æ–‡ä»¶"""
        logger.info("å¼€å§‹å…¨é‡åŒæ­¥...")
        
        if not self.config or 'monitors' not in self.config:
            logger.error("é…ç½®æ–‡ä»¶æ— æ•ˆ")
            return
        
        total_files = 0
        success_count = 0
        failed_count = 0
        skipped_count = 0
        
        for monitor in self.config['monitors']:
            if not monitor.get('enabled', True):
                continue
            
            source = Path(monitor['source'])
            # å…¼å®¹æ–°æ—§é…ç½®æ ¼å¼
            targets_config = monitor['targets']
            targets = []
            for t in targets_config:
                if isinstance(t, dict):
                    targets.append(Path(t['path']))
                else:
                    targets.append(Path(t))
            exclude = monitor.get('exclude_patterns', [])
            obfuscate = monitor.get('obfuscate_enabled', False)
            template_path = monitor.get('template_files_path')
            template_dir = Path(template_path) if template_path else None
            
            if not source.exists():
                logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {source}")
                continue
            
            logger.info(f"ğŸ”„ å¼€å§‹å…¨é‡åŒæ­¥: {source}, æ··æ·†: {obfuscate}")
            
            linker = FileLinker(obfuscate_enabled=obfuscate, db_engine=self.db_engine)
            session = get_session(self.db_engine)
            linked_dirs = set()  # è®°å½•å·²é“¾æ¥æ¨¡æ¿æ–‡ä»¶çš„ç›®å½•
            
            try:
                # é€’å½’æ‰«ææ‰€æœ‰æ–‡ä»¶
                for file_path in source.rglob('*'):
                    if file_path.is_file():
                        # åªå¤„ç†åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘+å­—å¹•ï¼‰
                        from backend.utils.obfuscator import FolderObfuscator
                        if not FolderObfuscator.is_media_file(file_path):
                            continue
                        
                        # æ£€æŸ¥æ˜¯å¦æ’é™¤
                        if linker.should_exclude(file_path, exclude):
                            continue
                        
                        total_files += 1
                        relative_path = file_path.relative_to(source)
                        file_size = file_path.stat().st_size
                        
                        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºç¡¬é“¾æ¥
                        for idx, target in enumerate(targets):
                            target_file = target / relative_path
                            
                            # æŸ¥è¯¢æˆ–åˆ›å»ºè®°å½•
                            record = session.query(LinkRecord).filter(
                                LinkRecord.source_file == str(file_path)
                            ).first()
                            
                            # åˆ¤æ–­æ˜¯å¦å·²åŒæ­¥è¿‡ï¼ˆæ£€æŸ¥å¯¹åº”ç½‘ç›˜å­—æ®µï¼‰
                            is_first_target = idx == 0
                            already_synced = False
                            if record:
                                if is_first_target and record.quark_target_file:
                                    already_synced = True
                                elif not is_first_target and record.baidu_target_file:
                                    already_synced = True
                            
                            if already_synced:
                                logger.debug(f"æ•°æ®åº“å·²æœ‰è®°å½•ï¼Œè·³è¿‡: {file_path} -> {target}")
                                skipped_count += 1
                                continue
                            
                            logger.info(f"åŒæ­¥: {file_path} -> {target_file}")
                            success, method, error, actual_target = linker.create_hardlink(
                                file_path, target_file,
                                source_base=source,
                                target_base=target
                            )
                            
                            if success:
                                success_count += 1
                                
                                # è‡ªåŠ¨é“¾æ¥æ¨¡æ¿æ–‡ä»¶åˆ°å‰§é›†æ–‡ä»¶å¤¹ï¼ˆåªé“¾æ¥ä¸€æ¬¡ï¼‰
                                if template_dir and template_dir.exists() and actual_target:
                                    target_show_dir = actual_target.parent
                                    if target_show_dir.name.startswith('Season'):
                                        target_show_dir = target_show_dir.parent
                                    
                                    dir_key = str(target_show_dir)
                                    if dir_key not in linked_dirs:
                                        linked_count = linker.link_template_files(target_show_dir, template_dir)
                                        if linked_count > 0:
                                            logger.info(f"âœ“ å·²é“¾æ¥ {linked_count} ä¸ªæ¨¡æ¿æ–‡ä»¶åˆ°: {target_show_dir}")
                                            linked_dirs.add(dir_key)
                                
                                # æ›´æ–°æˆ–åˆ›å»ºè®°å½•
                                if not record:
                                    from backend.utils.obfuscator import FolderObfuscator
                                    original_name = FolderObfuscator.extract_show_name(file_path)
                                    record = LinkRecord(
                                        source_file=str(file_path),
                                        original_name=original_name,
                                        file_size=file_size
                                    )
                                    session.add(record)
                                
                                # æ ¹æ®ç´¢å¼•åˆ¤æ–­æ˜¯å“ªä¸ªç½‘ç›˜
                                if is_first_target:
                                    record.quark_target_file = str(actual_target)
                                    record.quark_synced_at = datetime.now()
                                else:
                                    record.baidu_target_file = str(actual_target)
                                    record.baidu_synced_at = datetime.now()
                                
                                record.updated_at = datetime.now()
                            else:
                                failed_count += 1
                
                session.commit()
                logger.info(f"âœ… å…¨é‡åŒæ­¥å®Œæˆ: æ€»æ–‡ä»¶ {total_files}, æ–°å»º {success_count}, è·³è¿‡ {skipped_count}, å¤±è´¥ {failed_count}")
                
            except Exception as e:
                logger.error(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
                session.rollback()
                return {"success": False, "message": str(e)}
            finally:
                session.close()
        
        # å‘é€å…¨é‡åŒæ­¥å®Œæˆé€šçŸ¥
        self.notifier.notify_full_sync_complete(total_files, success_count, skipped_count, failed_count)
        
        return {
            "success": True,
            "total_files": total_files,
            "success_count": success_count,
            "skipped_count": skipped_count,
            "failed_count": failed_count
        }
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        # åœæ­¢æ‰€æœ‰handlerçš„TaoSyncé˜Ÿåˆ—
        for handler in self.handlers:
            if hasattr(handler, 'taosync_queue') and handler.taosync_queue:
                handler.taosync_queue.stop()
        
        if self.observer:
            self.observer.stop()
            self.observer.join()
            logger.info("ç›‘æ§æœåŠ¡å·²åœæ­¢")
