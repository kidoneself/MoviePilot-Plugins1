"""
ç½‘ç›˜æ‰¹é‡å¤„ç†ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†å¤šä¸ªç½‘ç›˜çš„è‡ªåŠ¨åŒ–æ“ä½œ
"""
import asyncio
import logging
from typing import Dict, List, Optional, Type
from sqlalchemy.orm import Session

from .base import CloudPanBase
from .baidu import BaiduPan
from .quark import QuarkPan

logger = logging.getLogger(__name__)


class CloudPanManager:
    """ç½‘ç›˜æ‰¹é‡å¤„ç†ç®¡ç†å™¨"""
    
    # æ”¯æŒçš„ç½‘ç›˜ç±»å‹
    SUPPORTED_PANS = {
        'baidu': BaiduPan,
        'quark': QuarkPan,
    }
    
    def __init__(self, headless: bool = False, cookies_dir: str = "./cookies"):
        """
        åˆå§‹åŒ–
        
        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
            cookies_dir: Cookieä¿å­˜ç›®å½•
        """
        self.headless = headless
        self.cookies_dir = cookies_dir
        self.pans: Dict[str, CloudPanBase] = {}
        
    async def init_pan(self, pan_type: str) -> Optional[CloudPanBase]:
        """
        åˆå§‹åŒ–æŒ‡å®šç½‘ç›˜
        
        Args:
            pan_type: ç½‘ç›˜ç±»å‹ï¼ˆbaidu/quarkï¼‰
            
        Returns:
            ç½‘ç›˜å®ä¾‹
        """
        if pan_type not in self.SUPPORTED_PANS:
            logger.error(f"ä¸æ”¯æŒçš„ç½‘ç›˜ç±»å‹: {pan_type}")
            return None
        
        if pan_type in self.pans:
            return self.pans[pan_type]
        
        try:
            pan_class = self.SUPPORTED_PANS[pan_type]
            pan = pan_class(headless=self.headless, cookies_dir=self.cookies_dir)
            await pan.start()
            
            # å¦‚æœæœ‰cookieæ–‡ä»¶ï¼Œè·³è¿‡ç™»å½•éªŒè¯ï¼ˆcookieå·²åœ¨startæ—¶åŠ è½½ï¼‰
            # ç›´æ¥å¼€å§‹ä½¿ç”¨ï¼Œå¦‚æœcookieæ— æ•ˆä¼šåœ¨æ“ä½œæ—¶å‘ç°
            if pan.cookies_file.exists():
                logger.info(f"âœ… æ£€æµ‹åˆ°{pan_type}ç½‘ç›˜cookieï¼Œè·³è¿‡ç™»å½•éªŒè¯")
                self.pans[pan_type] = pan
                return pan
            
            # æ²¡æœ‰cookieï¼Œéœ€è¦ç™»å½•
            if not await pan.login(wait_for_scan=True):
                logger.error(f"{pan_type}ç½‘ç›˜ç™»å½•å¤±è´¥")
                await pan.close()
                return None
            
            self.pans[pan_type] = pan
            return pan
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–{pan_type}ç½‘ç›˜å¤±è´¥: {e}")
            return None
    
    async def close_all(self):
        """å…³é—­æ‰€æœ‰ç½‘ç›˜"""
        for pan in self.pans.values():
            try:
                await pan.close()
            except Exception as e:
                logger.error(f"å…³é—­ç½‘ç›˜å¤±è´¥: {e}")
        self.pans.clear()
    
    async def batch_generate_links(
        self,
        db: Session,
        pan_type: str = 'baidu',
        target_path: str = None,
        expire_days: int = 0,
        original_name: str = None
    ) -> Dict[str, str]:
        """
        æ‰¹é‡ç”Ÿæˆåˆ†äº«é“¾æ¥å¹¶æ›´æ–°åˆ°æ•°æ®åº“
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            pan_type: ç½‘ç›˜ç±»å‹ï¼ˆbaidu/quarkï¼‰
            target_path: ç›®æ ‡ç½‘ç›˜è·¯å¾„å‰ç¼€ï¼ˆå¦‚ï¼š/å‰§é›†/å›½äº§å‰§é›†ï¼‰
            expire_days: æœ‰æ•ˆæœŸå¤©æ•°
            original_name: æŒ‡å®šå•ä¸ªå‰§é›†åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            {å‰§é›†å: åˆ†äº«é“¾æ¥}
        """
        from backend.models import CustomNameMapping
        
        # åˆå§‹åŒ–ç½‘ç›˜
        pan = await self.init_pan(pan_type)
        if not pan:
            return {}
        
        try:
            # æŸ¥è¯¢æ‰€æœ‰éœ€è¦ç”Ÿæˆé“¾æ¥çš„æ˜ å°„
            query = db.query(CustomNameMapping).filter(
                CustomNameMapping.enabled == True
            )
            
            # å¦‚æœæŒ‡å®šäº†å‰§é›†åï¼Œåªå¤„ç†è¯¥å‰§é›†
            if original_name:
                query = query.filter(CustomNameMapping.original_name == original_name)
            else:
                # æ‰¹é‡æ¨¡å¼ï¼šæ ¹æ®ç½‘ç›˜ç±»å‹è¿‡æ»¤æ²¡æœ‰é“¾æ¥çš„è®°å½•
                if pan_type == 'baidu':
                    query = query.filter(
                        (CustomNameMapping.baidu_link == None) |
                        (CustomNameMapping.baidu_link == '')
                    )
                elif pan_type == 'quark':
                    query = query.filter(
                        (CustomNameMapping.quark_link == None) |
                        (CustomNameMapping.quark_link == '')
                    )
            
            mappings = query.all()
            if original_name:
                logger.info(f"ğŸ“Š æ‰¾åˆ°æŒ‡å®šå‰§é›†: {original_name}")
            else:
                logger.info(f"ğŸ“Š æ‰¾åˆ° {len(mappings)} æ¡éœ€è¦ç”Ÿæˆ{pan_type}é“¾æ¥çš„è®°å½•")
            
            results = {}
            
            # æ‰¹é‡å¤„ç†
            for i, mapping in enumerate(mappings, 1):
                try:
                    # æ ¹æ®ç½‘ç›˜ç±»å‹ä½¿ç”¨å¯¹åº”çš„åç§°
                    folder_name = mapping.quark_name if pan_type == 'quark' else mapping.baidu_name
                    if not folder_name:
                        folder_name = mapping.original_name
                    
                    logger.info(f"â³ [{i}/{len(mappings)}] å¤„ç†: {folder_name}")
                    
                    # æ„å»ºå®Œæ•´è·¯å¾„
                    if target_path:
                        folder_path = f"{target_path}/{folder_name}"
                    else:
                        folder_path = folder_name
                    
                    # åˆ›å»ºåˆ†äº«é“¾æ¥
                    link = await pan.create_share_link(folder_name, expire_days)
                    
                    if link:
                        # æ›´æ–°åˆ°æ•°æ®åº“
                        if pan_type == 'baidu':
                            mapping.baidu_link = link
                        elif pan_type == 'quark':
                            mapping.quark_link = link
                        
                        db.commit()
                        results[mapping.original_name] = link
                        logger.info(f"âœ… [{i}/{len(mappings)}] æˆåŠŸ: {folder_name} -> {link}")
                    else:
                        logger.warning(f"âš ï¸ [{i}/{len(mappings)}] å¤±è´¥: {folder_name}")
                        results[mapping.original_name] = None
                    
                    # é¿å…é¢‘ç‡é™åˆ¶
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    logger.error(f"âŒ [{i}/{len(mappings)}] é”™è¯¯: {folder_name} - {e}")
                    results[mapping.original_name] = None
            
            # ç»Ÿè®¡æˆåŠŸæ•°é‡
            success_count = sum(1 for v in results.values() if v)
            logger.info(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼æˆåŠŸ: {success_count}/{len(results)}")
            logger.info("â„¹ï¸  æµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ã€‚å®Œæˆåæ‰‹åŠ¨å…³é—­æµè§ˆå™¨çª—å£ã€‚")
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆé“¾æ¥å¤±è´¥: {e}")
            logger.info("â„¹ï¸  æµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥é”™è¯¯ã€‚")
            return {}
        # ä¸è‡ªåŠ¨å…³é—­æµè§ˆå™¨ï¼Œæ–¹ä¾¿ç”¨æˆ·è°ƒè¯•
