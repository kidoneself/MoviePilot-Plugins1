from datetime import datetime, timedelta
import hashlib
import random
import re
import shutil
import threading
import traceback
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional

try:
    from .pinyin_map import PINYIN_MAP
except ImportError:
    PINYIN_MAP = {}

import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
from watchdog.observers.polling import PollingObserver

from app import schemas
from app.chain.media import MediaChain
from app.chain.storage import StorageChain
from app.chain.tmdb import TmdbChain
from app.chain.transfer import TransferChain
from app.core.config import settings
from app.core.context import MediaInfo
from app.core.event import eventmanager, Event
from app.core.metainfo import MetaInfoPath
from app.db.downloadhistory_oper import DownloadHistoryOper
from app.db.transferhistory_oper import TransferHistoryOper
from app.helper.directory import DirectoryHelper
from app.log import logger
from app.modules.filemanager import FileManagerModule
from app.plugins import _PluginBase
from app.schemas import NotificationType, TransferInfo, TransferDirectoryConf
from app.schemas.types import EventType, MediaType, SystemConfigKey
from app.utils.string import StringUtils
from app.utils.system import SystemUtils

lock = threading.Lock()


class FileMonitorHandler(FileSystemEventHandler):
    """
    ÁõÆÂΩïÁõëÊéßÂìçÂ∫îÁ±ª
    """

    def __init__(self, monpath: str, sync: Any, **kwargs):
        super(FileMonitorHandler, self).__init__(**kwargs)
        self._watch_path = monpath
        self.sync = sync

    def on_created(self, event):
        self.sync.event_handler(event=event, text="ÂàõÂª∫",
                                mon_path=self._watch_path, event_path=event.src_path)

    def on_moved(self, event):
        self.sync.event_handler(event=event, text="ÁßªÂä®",
                                mon_path=self._watch_path, event_path=event.dest_path)


class CloudLinkMonitor(_PluginBase):
    # Êèí‰ª∂ÂêçÁß∞
    plugin_name = "ÁõëÊéßËΩ¨ÁßªÊñá‰ª∂"
    # Êèí‰ª∂ÊèèËø∞
    plugin_desc = "ÁõëÊéßÁõÆÂΩïÊñá‰ª∂ÂèòÂåñÔºåÊîØÊåÅÁ°¨ÈìæÊé•ÂíåÂ§çÂà∂ÊîπHashÔºåÊãºÈü≥Ê∑∑Ê∑ÜÂâßÂêçÔºà‰øùÁïôÂàÜÁ±ªÁõÆÂΩïÔºâÔºåÊâπÊ¨°Ê±áÊÄªÈÄöÁü•„ÄÇ"
    # Êèí‰ª∂ÂõæÊ†á
    plugin_icon = "Linkease_A.png"
    # Êèí‰ª∂ÁâàÊú¨
    plugin_version = "3.5.1"
    # Êèí‰ª∂‰ΩúËÄÖ
    plugin_author = "thsrite"
    # ‰ΩúËÄÖ‰∏ªÈ°µ
    author_url = "https://github.com/thsrite"
    # Êèí‰ª∂ÈÖçÁΩÆÈ°πIDÂâçÁºÄ
    plugin_config_prefix = "cloudlinkmonitor_"
    # Âä†ËΩΩÈ°∫Â∫è
    plugin_order = 4
    # ÂèØ‰ΩøÁî®ÁöÑÁî®Êà∑Á∫ßÂà´
    auth_level = 1

    # ÁßÅÊúâÂ±ûÊÄß
    _scheduler = None
    transferhis = None
    downloadhis = None
    transferchian = None
    tmdbchain = None
    storagechain = None
    _observer = []
    _enabled = False
    _notify = False
    _onlyonce = False
    _cron = None
    filetransfer = None
    mediaChain = None
    _size = 0
    _monitor_dirs = ""
    _exclude_keywords = ""
    _transfer_type = "link"
    # Â≠òÂÇ®Ê∫êÁõÆÂΩï‰∏éÁõÆÁöÑÁõÆÂΩïÂÖ≥Á≥ª
    _dirconf: Dict[str, Optional[Path]] = {}
    # Â≠òÂÇ®Ê∫êÁõÆÂΩïËΩ¨ÁßªÊñπÂºè
    _transferconf: Dict[str, Optional[str]] = {}
    # ÈÄÄÂá∫‰∫ã‰ª∂
    _event = threading.Event()
    # ÊâπÊ¨°Ê±áÊÄªÁõ∏ÂÖ≥
    _batch_files = []  # ÊâπÊ¨°Â§ÑÁêÜÁöÑÊñá‰ª∂ÂàóË°®
    _last_process_time = None  # ÊúÄÂêéÂ§ÑÁêÜÊó∂Èó¥
    _summary_timer = None  # Ê±áÊÄªÂÆöÊó∂Âô®
    _batch_lock = threading.Lock()  # ÊâπÊ¨°Êï∞ÊçÆÈîÅ

    def init_plugin(self, config: dict = None):
        self.transferhis = TransferHistoryOper()
        self.downloadhis = DownloadHistoryOper()
        self.transferchian = TransferChain()
        self.tmdbchain = TmdbChain()
        self.mediaChain = MediaChain()
        self.storagechain = StorageChain()
        self.filetransfer = FileManagerModule()
        # Ê∏ÖÁ©∫ÈÖçÁΩÆ
        self._dirconf = {}
        self._transferconf = {}

        # ËØªÂèñÈÖçÁΩÆ
        if config:
            self._enabled = config.get("enabled")
            self._notify = config.get("notify")
            self._onlyonce = config.get("onlyonce")
            self._transfer_type = config.get("transfer_type") or "link"
            self._monitor_dirs = config.get("monitor_dirs") or ""
            self._exclude_keywords = config.get("exclude_keywords") or ""
            self._cron = config.get("cron")
            self._size = config.get("size") or 0

        # ÂÅúÊ≠¢Áé∞Êúâ‰ªªÂä°
        self.stop_service()

        if self._enabled or self._onlyonce:
            # ÂÆöÊó∂ÊúçÂä°ÁÆ°ÁêÜÂô®
            self._scheduler = BackgroundScheduler(timezone=settings.TZ)

            # ËØªÂèñÁõÆÂΩïÈÖçÁΩÆ
            monitor_dirs = self._monitor_dirs.split("\n")
            if not monitor_dirs:
                return
            for mon_path in monitor_dirs:
                # Ê†ºÂºèÊ∫êÁõÆÂΩï:ÁõÆÁöÑÁõÆÂΩï
                if not mon_path:
                    continue

                # Ëá™ÂÆö‰πâËΩ¨ÁßªÊñπÂºèÔºàÊîØÊåÅlinkÂíåcopyhashÔºâ
                _transfer_type = self._transfer_type
                if mon_path.count("#") == 1:
                    _transfer_type = mon_path.split("#")[1]
                    mon_path = mon_path.split("#")[0]

                # Â≠òÂÇ®ÁõÆÁöÑÁõÆÂΩï
                if SystemUtils.is_windows():
                    if mon_path.count(":") > 1:
                        paths = [mon_path.split(":")[0] + ":" + mon_path.split(":")[1],
                                 mon_path.split(":")[2] + ":" + mon_path.split(":")[3]]
                    else:
                        paths = [mon_path]
                else:
                    paths = mon_path.split(":")

                # ÁõÆÁöÑÁõÆÂΩï
                target_path = None
                if len(paths) > 1:
                    mon_path = paths[0]
                    target_path = Path(paths[1])
                    self._dirconf[mon_path] = target_path
                else:
                    self._dirconf[mon_path] = None

                # ËΩ¨ÁßªÊñπÂºè
                self._transferconf[mon_path] = _transfer_type

                # ÂêØÁî®ÁõÆÂΩïÁõëÊéß
                if self._enabled:
                    # Ê£ÄÊü•Â™í‰ΩìÂ∫ìÁõÆÂΩïÊòØ‰∏çÊòØ‰∏ãËΩΩÁõÆÂΩïÁöÑÂ≠êÁõÆÂΩï
                    try:
                        if target_path and target_path.is_relative_to(Path(mon_path)):
                            logger.warn(f"{target_path} ÊòØÁõëÊéßÁõÆÂΩï {mon_path} ÁöÑÂ≠êÁõÆÂΩïÔºåÊó†Ê≥ïÁõëÊéß")
                            self.systemmessage.put(f"{target_path} ÊòØ‰∏ãËΩΩÁõÆÂΩï {mon_path} ÁöÑÂ≠êÁõÆÂΩïÔºåÊó†Ê≥ïÁõëÊéß")
                            continue
                    except Exception as e:
                        logger.debug(str(e))
                        pass

                    try:
                        # ‰ΩøÁî®ÈªòËÆ§Observer
                        observer = Observer(timeout=10)
                        self._observer.append(observer)
                        observer.schedule(FileMonitorHandler(mon_path, self), path=mon_path, recursive=True)
                        observer.daemon = True
                        observer.start()
                        logger.info(f"{mon_path} ÁöÑ‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÊúçÂä°ÂêØÂä®")
                    except Exception as e:
                        err_msg = str(e)
                        if "inotify" in err_msg and "reached" in err_msg:
                            logger.warn(
                                f"‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÊúçÂä°ÂêØÂä®Âá∫Áé∞ÂºÇÂ∏∏Ôºö{err_msg}ÔºåËØ∑Âú®ÂÆø‰∏ªÊú∫‰∏äÔºà‰∏çÊòØdockerÂÆπÂô®ÂÜÖÔºâÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Âπ∂ÈáçÂêØÔºö"
                                + """
                                     echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf
                                     echo fs.inotify.max_user_instances=524288 | sudo tee -a /etc/sysctl.conf
                                     sudo sysctl -p
                                     """)
                        else:
                            logger.error(f"{mon_path} ÂêØÂä®ÁõÆ‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂ§±Ë¥•Ôºö{err_msg}")
                        self.systemmessage.put(f"{mon_path} ÂêØÂä®‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂ§±Ë¥•Ôºö{err_msg}")

            # ËøêË°å‰∏ÄÊ¨°ÂÆöÊó∂ÊúçÂä°
            if self._onlyonce:
                logger.info("‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÊúçÂä°ÂêØÂä®ÔºåÁ´ãÂç≥ËøêË°å‰∏ÄÊ¨°")
                self._scheduler.add_job(name="‰∫ëÁõòÂÆûÊó∂ÁõëÊéß",
                                        func=self.sync_all, trigger='date',
                                        run_date=datetime.now(
                                            tz=pytz.timezone(settings.TZ)) + timedelta(seconds=3)
                                        )
                # ÂÖ≥Èó≠‰∏ÄÊ¨°ÊÄßÂºÄÂÖ≥
                self._onlyonce = False
                # ‰øùÂ≠òÈÖçÁΩÆ
                self.__update_config()

            # ÂêØÂä®ÂÆöÊó∂ÊúçÂä°
            if self._scheduler.get_jobs():
                self._scheduler.print_jobs()
                self._scheduler.start()

    def __update_config(self):
        """
        Êõ¥Êñ∞ÈÖçÁΩÆ
        """
        self.update_config({
            "enabled": self._enabled,
            "notify": self._notify,
            "onlyonce": self._onlyonce,
            "transfer_type": self._transfer_type,
            "monitor_dirs": self._monitor_dirs,
            "exclude_keywords": self._exclude_keywords,
            "cron": self._cron,
            "size": self._size,
        })

    @eventmanager.register(EventType.PluginAction)
    def remote_sync(self, event: Event):
        """
        ËøúÁ®ãÂëΩ‰ª§Â§ÑÁêÜ
        """
        if event:
            event_data = event.event_data
            if not event_data:
                return
            
            action = event_data.get("action")
            channel = event_data.get("channel")
            user = event_data.get("user")
            
            # ÂÖ®ÈáèÂêåÊ≠•ÂëΩ‰ª§
            if action == "cloud_link_sync":
                self.post_message(channel=channel, title="ÂºÄÂßãÂêåÊ≠•‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÁõÆÂΩï ...", userid=user)
                self.sync_all()
                self.post_message(channel=channel, title="‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÁõÆÂΩïÂêåÊ≠•ÂÆåÊàêÔºÅ", userid=user)
            
            # ÂêåÊ≠•Ê£ÄÊü•ÂëΩ‰ª§
            elif action == "sync_check":
                self.post_message(channel=channel, title="ÂºÄÂßãÊ£ÄÊü•ÂêåÊ≠•Áä∂ÊÄÅ ...", userid=user)
                self.sync_check(channel=channel, user=user)
                self.post_message(channel=channel, title="ÂêåÊ≠•Áä∂ÊÄÅÊ£ÄÊü•ÂÆåÊàêÔºÅ", userid=user)

    def sync_all(self):
        """
        Á´ãÂç≥ËøêË°å‰∏ÄÊ¨°ÔºåÂÖ®ÈáèÂêåÊ≠•ÁõÆÂΩï‰∏≠ÊâÄÊúâÊñá‰ª∂
        """
        logger.info("ÂºÄÂßãÂÖ®ÈáèÂêåÊ≠•‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÁõÆÂΩï ...")
        # ÈÅçÂéÜÊâÄÊúâÁõëÊéßÁõÆÂΩï
        for mon_path in self._dirconf.keys():
            logger.info(f"ÂºÄÂßãÂ§ÑÁêÜÁõëÊéßÁõÆÂΩï {mon_path} ...")
            list_files = SystemUtils.list_files(Path(mon_path), settings.RMT_MEDIAEXT)
            logger.info(f"ÁõëÊéßÁõÆÂΩï {mon_path} ÂÖ±ÂèëÁé∞ {len(list_files)} ‰∏™Êñá‰ª∂")
            # ÈÅçÂéÜÁõÆÂΩï‰∏ãÊâÄÊúâÊñá‰ª∂
            for file_path in list_files:
                logger.info(f"ÂºÄÂßãÂ§ÑÁêÜÊñá‰ª∂ {file_path} ...")
                self.__handle_file(event_path=str(file_path), mon_path=mon_path)
    
    def sync_check(self, channel=None, user=None):
        """
        Ê£ÄÊü•ÂêåÊ≠•Áä∂ÊÄÅÔºåÂØπÊØîÊ∫êÁõÆÂΩïÂíåÁõÆÊ†áÁõÆÂΩï
        """
        logger.info("ÂºÄÂßãÊ£ÄÊü•ÂêåÊ≠•Áä∂ÊÄÅ ...")
        
        # ÈÅçÂéÜÊâÄÊúâÁõëÊéßÁõÆÂΩï
        for mon_path, target_path in self._dirconf.items():
            if not target_path:
                continue
            
            mon_path_obj = Path(mon_path)
            if not mon_path_obj.exists():
                continue
            
            # Êâ´ÊèèÊ∫êÁõÆÂΩïÔºåÊåâ‰∏ÄÁ∫ßÂ≠êÁõÆÂΩïÂàÜÁªÑÔºàÂ™í‰ΩìÊñá‰ª∂Â§πÔºâ
            media_folders = {}
            for item in mon_path_obj.iterdir():
                if item.is_dir():
                    # ÁªüËÆ°ËØ•Êñá‰ª∂Â§π‰∏ãÁöÑÂ™í‰ΩìÊñá‰ª∂
                    files = SystemUtils.list_files(item, settings.RMT_MEDIAEXT)
                    if files:
                        media_folders[item.name] = {
                            'path': str(item),
                            'files': [f.name for f in files]
                        }
            
            # ÂØπÊØè‰∏™Â™í‰ΩìÊñá‰ª∂Â§πÂèëÈÄÅÈÄöÁü•
            for folder_name, folder_info in media_folders.items():
                source_files = folder_info['files']
                source_count = len(source_files)
                
                # Ê£ÄÊü•ÁõÆÊ†áÁõÆÂΩïÊòØÂê¶Â≠òÂú®ÂØπÂ∫îÊñá‰ª∂Â§π
                target_folders = []
                target_count = 0
                target_files_list = []
                
                # ÈÅçÂéÜÁõÆÊ†áÁõÆÂΩïÊü•ÊâæÂèØËÉΩÁöÑÂåπÈÖç
                if target_path.exists():
                    for target_item in target_path.rglob('*'):
                        if target_item.is_dir():
                            target_files = SystemUtils.list_files(target_item, settings.RMT_MEDIAEXT)
                            if target_files:
                                target_folders.append({
                                    'name': target_item.name,
                                    'relative': str(target_item.relative_to(target_path)),
                                    'files': [f.name for f in target_files]
                                })
                
                # Â∞ùËØïÂåπÈÖçÁõÆÊ†áÊñá‰ª∂Â§πÔºàÈÄöËøáÊñá‰ª∂Êï∞ÈáèÊàñÊ®°Á≥äÂåπÈÖçÔºâ
                matched_target = None
                for tf in target_folders:
                    # ÁÆÄÂçïÂåπÈÖçÔºöÊñá‰ª∂Êï∞ÈáèÁõ∏Âêå
                    if len(tf['files']) == source_count:
                        matched_target = tf
                        break
                
                if matched_target:
                    target_count = len(matched_target['files'])
                    target_info = f"üìÅ ÁõÆÊ†áÔºö{matched_target['relative']}/\n"
                    for f in matched_target['files']:
                        target_info += f"  ‚àô {f}\n"
                    status = f"‚úÖ Ê∫ê{source_count}‰∏™ = ÁõÆÊ†á{target_count}‰∏™"
                else:
                    target_info = "‚ùå Êú™ÊâæÂà∞Êàñ‰∏çÂ≠òÂú®\n"
                    status = f"‚ö†Ô∏è Ê∫ê{source_count}‰∏™ ‚â† ÁõÆÊ†á0‰∏™"
                
                # ÊûÑÂª∫ÈÄöÁü•ÂÜÖÂÆπ
                source_info = f"üìÅ Ê∫êÔºö{folder_info['path']}/\n"
                for f in source_files:
                    source_info += f"  ‚àô {f}\n"
                
                message = (
                    f"üìÇ {folder_name}\n\n"
                    f"{source_info}\n"
                    f"{target_info}\n"
                    f"{status}"
                )
                
                # ÂèëÈÄÅÈÄöÁü•
                self.post_message(
                    channel=channel,
                    title=f"üìä {folder_name}",
                    text=message,
                    userid=user
                )
                
        logger.info("ÂêåÊ≠•Áä∂ÊÄÅÊ£ÄÊü•ÂÆåÊàê")
        logger.info("ÂÖ®ÈáèÂêåÊ≠•‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÁõÆÂΩïÂÆåÊàêÔºÅ")

    def event_handler(self, event, mon_path: str, text: str, event_path: str):
        """
        Â§ÑÁêÜÊñá‰ª∂ÂèòÂåñ
        :param event: ‰∫ã‰ª∂
        :param mon_path: ÁõëÊéßÁõÆÂΩï
        :param text: ‰∫ã‰ª∂ÊèèËø∞
        :param event_path: ‰∫ã‰ª∂Êñá‰ª∂Ë∑ØÂæÑ
        """
        if not event.is_directory:
            # Êñá‰ª∂ÂèëÁîüÂèòÂåñ
            logger.debug("Êñá‰ª∂%sÔºö%s" % (text, event_path))
            self.__handle_file(event_path=event_path, mon_path=mon_path)
    
    def __add_to_batch(self, file_info: dict):
        """
        Ê∑ªÂä†Êñá‰ª∂Âà∞ÊâπÊ¨°Ê±áÊÄª
        :param file_info: Êñá‰ª∂Â§ÑÁêÜ‰ø°ÊÅØ
        """
        with self._batch_lock:
            self._batch_files.append(file_info)
            self._last_process_time = datetime.now()
            
            # ÈáçÁΩÆÊ±áÊÄªÂÆöÊó∂Âô®
            if self._summary_timer:
                self._summary_timer.cancel()
            
            # 30ÁßíÂêéÊ£ÄÊü•ÊòØÂê¶ÂèëÈÄÅÊ±áÊÄª
            self._summary_timer = threading.Timer(30.0, self.__check_and_send_summary)
            self._summary_timer.daemon = True
            self._summary_timer.start()
    
    def __check_and_send_summary(self):
        """
        Ê£ÄÊü•Âπ∂ÂèëÈÄÅÊâπÊ¨°Ê±áÊÄªÈÄöÁü•
        """
        with self._batch_lock:
            if not self._batch_files:
                return
            
            # Ê£ÄÊü•ÊòØÂê¶30ÁßíÂÜÖÊó†Êñ∞Êñá‰ª∂
            if self._last_process_time and (datetime.now() - self._last_process_time).total_seconds() >= 30:
                self.__send_batch_summary()
    
    def __send_batch_summary(self):
        """
        ÂèëÈÄÅÊâπÊ¨°Ê±áÊÄªÈÄöÁü•
        """
        if not self._batch_files:
            return
        
        try:
            # ÁªüËÆ°‰ø°ÊÅØ
            total_files = len(self._batch_files)
            total_size = sum(f.get('size', 0) for f in self._batch_files)
            
            # ËÆ°ÁÆóÁî®Êó∂
            start_time = self._batch_files[0].get('time')
            end_time = self._batch_files[-1].get('time')
            if start_time and end_time:
                duration = (end_time - start_time).total_seconds()
                duration_str = f"{int(duration // 60)}ÂàÜ{int(duration % 60)}Áßí" if duration >= 60 else f"{int(duration)}Áßí"
            else:
                duration_str = "Êú™Áü•"
            
            # ÊåâÁõÆÂΩïÂàÜÁªÑÁªüËÆ°
            dir_stats = {}
            for f in self._batch_files:
                source_dir = f.get('source_dir', 'Êú™Áü•')
                target_dir = f.get('target_dir', 'Êú™Áü•')
                key = f"{source_dir}‚Üí{target_dir}"
                
                if key not in dir_stats:
                    dir_stats[key] = {
                        'source': source_dir,
                        'target': target_dir,
                        'count': 0,
                        'size': 0
                    }
                dir_stats[key]['count'] += 1
                dir_stats[key]['size'] += f.get('size', 0)
            
            # ÊûÑÂª∫ÁõÆÂΩïÊ±áÊÄªÊñáÊú¨
            dir_summary_lines = []
            for i, stats in enumerate(dir_stats.values(), 1):
                size_gb = stats['size'] / (1024**3)
                dir_summary_lines.append(
                    f"  {i}. ÔøΩ {stats['source']} ({stats['count']}‰∏™ | {size_gb:.1f}GB)\n"
                    f"     ‚¨áÔ∏è  \n"
                    f"     ÔøΩ {stats['target']}"
                )
            dir_summary = "\n\n".join(dir_summary_lines)
            
            # Ê†ºÂºèÂåñÊÄªÂ§ßÂ∞è
            if total_size >= 1024**3:
                size_str = f"{total_size / (1024**3):.2f} GB"
            elif total_size >= 1024**2:
                size_str = f"{total_size / (1024**2):.2f} MB"
            else:
                size_str = f"{total_size / 1024:.2f} KB"
            
            # ÂèëÈÄÅÈÄöÁü•
            notify_text = (
                f"üìä Êú¨ÊâπÊ¨°ÁªüËÆ°\n"
                f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                f"üì¶ Êñá‰ª∂Êï∞ÈáèÔºö{total_files} ‰∏™\n"
                f"üíæ ÊÄªÂ§ßÂ∞èÔºö{size_str}\n"
                f"‚è±Ô∏è ËÄóÊó∂Ôºö{duration_str}\n"
                f"üîó ÊñπÂºèÔºö{self._batch_files[0].get('method', 'Êú™Áü•')}\n\n"
                f"üìÇ ÁõÆÂΩïËØ¶ÊÉÖ\n"
                f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                f"{dir_summary}"
            )
            
            self.post_message(
                mtype=NotificationType.Manual,
                title="‚úÖ ÊâπÊ¨°Â§ÑÁêÜÂÆåÊàêÔºÅ",
                text=notify_text
            )
            
            logger.info(f"ÊâπÊ¨°Ê±áÊÄªÈÄöÁü•Â∑≤ÂèëÈÄÅÔºöÂÖ±Â§ÑÁêÜ {total_files} ‰∏™Êñá‰ª∂")
            
        except Exception as e:
            logger.error(f"ÂèëÈÄÅÊâπÊ¨°Ê±áÊÄªÈÄöÁü•Â§±Ë¥•Ôºö{str(e)}")
        finally:
            # Ê∏ÖÁ©∫ÊâπÊ¨°ÂàóË°®
            self._batch_files = []
            self._last_process_time = None
    
    def __obfuscate_name(self, name: str) -> str:
        """
        Ê∑∑Ê∑ÜÂâßÂêçÔºö‰∏≠Êñá+ÊãºÈü≥+ÁâπÊÆäÂ≠óÁ¨¶
        :param name: ÂéüÂßãÂêçÁß∞
        :return: Ê∑∑Ê∑ÜÂêéÁöÑÂêçÁß∞
        """
        # ÁâπÊÆäÂ≠óÁ¨¶Â∫ìÔºàÂè™‰ΩøÁî®ÊúÄ‰øùÂÆàÁöÑÁªùÂØπÂÆâÂÖ®Â≠óÁ¨¶Ôºâ
        special_chars = ['_', '-']
        
        # ‰ΩøÁî®MD5Á°Æ‰øùÁ°ÆÂÆöÊÄß
        hash_obj = hashlib.md5(name.encode('utf-8'))
        hash_int = int(hash_obj.hexdigest(), 16)
        
        result = []
        for i, char in enumerate(name):
            # Ê†πÊçÆhashÂÜ≥ÂÆöÂ§ÑÁêÜÊñπÂºè
            choice = (hash_int >> (i * 3)) % 2
            
            if '\u4e00' <= char <= '\u9fff':  # ‰∏≠ÊñáÂ≠óÁ¨¶
                if choice == 0:
                    # ‰øùÁïô‰∏≠Êñá
                    result.append(char)
                else:
                    # ËΩ¨ÊãºÈü≥
                    pinyin = PINYIN_MAP.get(char, char)
                    result.append(pinyin)
                
                # Ê∑ªÂä†ÁâπÊÆäÂ≠óÁ¨¶ÔºàÊ¶ÇÁéá30%Ôºâ
                if (hash_int >> (i * 5)) % 10 < 3:
                    special_idx = (hash_int >> (i * 7)) % len(special_chars)
                    result.append(special_chars[special_idx])
            else:
                # Èùû‰∏≠ÊñáÂ≠óÁ¨¶‰øùÊåÅ‰∏çÂèò
                result.append(char)
        
        return ''.join(result)
    
    def __generate_new_paths(self, relative_path: Path, target: Path, file_name: str):
        """
        ÁîüÊàêÊ∑∑Ê∑ÜÂêéÁöÑÁõÆÂΩïÂíåÊñá‰ª∂Âêç
        :param relative_path: Áõ∏ÂØπË∑ØÂæÑ
        :param target: ÁõÆÊ†áÊ†πÁõÆÂΩï
        :param file_name: ÂéüÂßãÊñá‰ª∂Âêç
        :return: (ÁõÆÊ†áÁõÆÂΩï, Êñ∞Êñá‰ª∂Âêç)
        """
        # Â§ÑÁêÜÁõÆÂΩïÂêçÔºöÂè™Ê∑∑Ê∑ÜÂâßÂêçÊñá‰ª∂Â§πÔºå‰øùÁïôÂàÜÁ±ªÁõÆÂΩïÂíåSeasonÁõÆÂΩï
        if relative_path.parent != Path('.'):
            parent_parts = list(relative_path.parent.parts)
            new_parent_parts = []
            
            for i, dir_name in enumerate(parent_parts):
                # ‰øùÁïôSeasonÁõÆÂΩï‰∏çÂèò
                if re.match(r'^Season\s+\d+$', dir_name, re.IGNORECASE):
                    new_parent_parts.append(dir_name)
                    logger.info(f"‰øùÁïôSeasonÁõÆÂΩï: {dir_name}")
                    continue
                
                # ‰øùÁïôÁ¨¨‰∏ÄÂ±ÇÂàÜÁ±ªÁõÆÂΩï‰∏çÂèòÔºàÁîµËßÜÂâß„ÄÅÁîµÂΩ±Á≠âÔºâ
                if i == 0:
                    new_parent_parts.append(dir_name)
                    logger.info(f"‰øùÁïôÂàÜÁ±ªÁõÆÂΩï: {dir_name}")
                    continue
                
                # ÊèêÂèñÂπ¥‰ªΩÔºàÂ¶ÇÊûúÊúâÔºâ
                year_match = re.search(r'\((\d{4})\)$', dir_name)
                year_suffix = f" ({year_match.group(1)})" if year_match else ""
                
                # ÂéªÊéâÂπ¥‰ªΩÂêéÁöÑÁõÆÂΩïÂêç
                dir_name_without_year = re.sub(r'\s*\(\d{4}\)$', '', dir_name)
                
                # Ê∑∑Ê∑ÜÂâßÂêç
                obfuscated_name = self.__obfuscate_name(dir_name_without_year)
                
                # ÊûÑÂª∫Êñ∞ÁõÆÂΩïÂêçÔºöÊ∑∑Ê∑ÜÂêç + Âπ¥‰ªΩ
                new_dir = obfuscated_name + year_suffix
                new_parent_parts.append(new_dir)
                logger.info(f"ÁõÆÂΩïÂêçÊ∑∑Ê∑Ü: {dir_name} -> {new_dir}")
            
            target_dir = target / Path(*new_parent_parts) if new_parent_parts else target
        else:
            target_dir = target
        
        # Â§ÑÁêÜÊñá‰ª∂ÂêçÔºöÊèêÂèñS01E01ÂíåËßÜÈ¢ëÊ†ºÂºè
        file_stem = Path(file_name).stem
        file_suffix = Path(file_name).suffix
        
        # ÊèêÂèñÂ≠£ÈõÜÂè∑ÔºàS01E01Ê†ºÂºèÔºâ
        season_episode = re.search(r'[Ss](\d+)[Ee](\d+)', file_stem)
        
        # ÊèêÂèñËßÜÈ¢ëÊ†ºÂºè‰ø°ÊÅØÔºà1080p, 4K, 2160pÁ≠âÔºâ
        video_format = re.search(r'(\d{3,4}[pP]|[248][kK]|[hH][dD]|[uU][hH][dD])', file_stem)
        
        if season_episode:
            # ÁîµËßÜÂâßÔºöS01E01-1080p.mkv
            new_stem = f"S{season_episode.group(1)}E{season_episode.group(2)}"
            if video_format:
                new_stem += f"-{video_format.group(1)}"
            logger.info(f"ÁîµËßÜÂâßÊñá‰ª∂Âêç: {new_stem}")
        elif video_format:
            # ÁîµÂΩ±Ôºö1080p.mkv
            new_stem = video_format.group(1)
            logger.info(f"ÁîµÂΩ±Êñá‰ª∂Âêç: {new_stem}")
        else:
            # Ê≤°ÊúâËØÜÂà´Âà∞Ê†ºÂºèÔºå‰ΩøÁî®movie‰Ωú‰∏∫ÂâçÁºÄ
            new_stem = "movie"
            logger.info(f"Êú™ËØÜÂà´Âà∞Ê†ºÂºèÔºå‰ΩøÁî®ÈªòËÆ§Êñá‰ª∂Âêç: {new_stem}")
        
        new_file_name = f"{new_stem}{file_suffix}"
        
        return target_dir, new_file_name

    def __handle_file(self, event_path: str, mon_path: str):
        """
        ÂêåÊ≠•‰∏Ä‰∏™Êñá‰ª∂
        :param event_path: ‰∫ã‰ª∂Êñá‰ª∂Ë∑ØÂæÑ
        :param mon_path: ÁõëÊéßÁõÆÂΩï
        """
        file_path = Path(event_path)
        try:
            if not file_path.exists():
                return
            # ÂÖ®Á®ãÂä†ÈîÅ
            with lock:
                # Êü•ËØ¢ËΩ¨ÁßªÊñπÂºèÔºàÊèêÂâçËé∑ÂèñÔºåÁî®‰∫éÂà§Êñ≠ÊòØÂê¶Ë∑≥ËøáÂéÜÂè≤Ê£ÄÊü•Ôºâ
                transfer_type = self._transferconf.get(mon_path)
                
                # copyhashÊ®°Âºè‰∏çÊ£ÄÊü•ÂéÜÂè≤ËÆ∞ÂΩïÔºåÂÖÅËÆ∏ÈáçÂ§çÂ§ÑÁêÜ
                if transfer_type != "copyhash":
                    transfer_history = self.transferhis.get_by_src(event_path)
                    if transfer_history:
                        logger.info("Êñá‰ª∂Â∑≤Â§ÑÁêÜËøáÔºö%s" % event_path)
                        return

                # ÂõûÊî∂Á´ôÂèäÈöêËóèÁöÑÊñá‰ª∂‰∏çÂ§ÑÁêÜ
                if event_path.find('/@Recycle/') != -1 \
                        or event_path.find('/#recycle/') != -1 \
                        or event_path.find('/.') != -1 \
                        or event_path.find('/@eaDir') != -1:
                    logger.debug(f"{event_path} ÊòØÂõûÊî∂Á´ôÊàñÈöêËóèÁöÑÊñá‰ª∂")
                    return

                # ÂëΩ‰∏≠ËøáÊª§ÂÖ≥ÈîÆÂ≠ó‰∏çÂ§ÑÁêÜ
                if self._exclude_keywords:
                    for keyword in self._exclude_keywords.split("\n"):
                        if keyword and re.findall(keyword, event_path):
                            logger.info(f"{event_path} ÂëΩ‰∏≠ËøáÊª§ÂÖ≥ÈîÆÂ≠ó {keyword}Ôºå‰∏çÂ§ÑÁêÜ")
                            return

                # Êï¥ÁêÜÂ±èËîΩËØç‰∏çÂ§ÑÁêÜ
                transfer_exclude_words = self.systemconfig.get(SystemConfigKey.TransferExcludeWords)
                if transfer_exclude_words:
                    for keyword in transfer_exclude_words:
                        if not keyword:
                            continue
                        if keyword and re.search(r"%s" % keyword, event_path, re.IGNORECASE):
                            logger.info(f"{event_path} ÂëΩ‰∏≠Êï¥ÁêÜÂ±èËîΩËØç {keyword}Ôºå‰∏çÂ§ÑÁêÜ")
                            return

                # ‰∏çÊòØÂ™í‰ΩìÊñá‰ª∂‰∏çÂ§ÑÁêÜ
                if file_path.suffix not in settings.RMT_MEDIAEXT:
                    logger.debug(f"{event_path} ‰∏çÊòØÂ™í‰ΩìÊñá‰ª∂")
                    return

                # Âà§Êñ≠ÊòØ‰∏çÊòØËìùÂÖâÁõÆÂΩï
                if re.search(r"BDMV[/\\]STREAM", event_path, re.IGNORECASE):
                    # Êà™ÂèñBDMVÂâçÈù¢ÁöÑË∑ØÂæÑ
                    blurray_dir = event_path[:event_path.find("BDMV")]
                    file_path = Path(blurray_dir)
                    logger.info(f"{event_path} ÊòØËìùÂÖâÁõÆÂΩïÔºåÊõ¥Ê≠£Êñá‰ª∂Ë∑ØÂæÑ‰∏∫Ôºö{str(file_path)}")
                    # Êü•ËØ¢ÂéÜÂè≤ËÆ∞ÂΩïÔºåÂ∑≤ËΩ¨ÁßªÁöÑ‰∏çÂ§ÑÁêÜ
                    if self.transferhis.get_by_src(str(file_path)):
                        logger.info(f"{file_path} Â∑≤Êï¥ÁêÜËøá")
                        return

                # ÂÖÉÊï∞ÊçÆ
                file_meta = MetaInfoPath(file_path)
                if not file_meta.name:
                    logger.error(f"{file_path.name} Êó†Ê≥ïËØÜÂà´ÊúâÊïà‰ø°ÊÅØ")
                    return

                # Âà§Êñ≠Êñá‰ª∂Â§ßÂ∞è
                if self._size and float(self._size) > 0 and file_path.stat().st_size < float(self._size) * 1024 ** 3:
                    logger.info(f"{file_path} Êñá‰ª∂Â§ßÂ∞èÂ∞è‰∫éÁõëÊéßÊñá‰ª∂Â§ßÂ∞èÔºå‰∏çÂ§ÑÁêÜ")
                    return

                # Êü•ËØ¢ËΩ¨ÁßªÁõÆÁöÑÁõÆÂΩï
                target: Path = self._dirconf.get(mon_path)

                # linkÊ®°ÂºèÔºöÁ°¨ÈìæÊé•+ÊîπÂêçÔºà‰∏çÊîπhashÔºâ
                if transfer_type == "link":
                    logger.info(f"linkÊ®°ÂºèÔºöÂºÄÂßãÂ§ÑÁêÜ {file_path.name}")
                    try:
                        if not target:
                            logger.error(f"linkÊ®°ÂºèÔºöÊú™ÈÖçÁΩÆÁõëÊéßÁõÆÂΩï {mon_path} ÁöÑÁõÆÁöÑÁõÆÂΩï")
                            return
                        
                        # ËÆ°ÁÆóÁõ∏ÂØπË∑ØÂæÑ
                        mon_path_obj = Path(mon_path)
                        relative_path = file_path.relative_to(mon_path_obj)
                        logger.info(f"linkÊ®°ÂºèÔºöÁõ∏ÂØπË∑ØÂæÑ {relative_path}")
                        
                        # ÁîüÊàêÊñ∞ÁöÑÁõÆÂΩïÂíåÊñá‰ª∂Âêç
                        target_dir, new_file_name = self.__generate_new_paths(relative_path, target, file_path.name)
                        target_file = target_dir / new_file_name
                        logger.info(f"linkÊ®°ÂºèÔºöÁõÆÊ†áË∑ØÂæÑ {target_file}")
                        
                        # Á°Æ‰øùÁõÆÊ†áÁõÆÂΩïÂ≠òÂú®
                        target_dir.mkdir(parents=True, exist_ok=True)
                        
                        # Â∞ùËØïÁ°¨ÈìæÊé•ÔºåÂ§±Ë¥•ÂàôÂ§çÂà∂
                        try:
                            logger.info(f"linkÊ®°ÂºèÔºöÂ∞ùËØïÂàõÂª∫Á°¨ÈìæÊé• {file_path} -> {target_file}")
                            import os
                            os.link(str(file_path), str(target_file))
                            transfer_method = "Á°¨ÈìæÊé•"
                            logger.info(f"linkÊ®°ÂºèÔºöÁ°¨ÈìæÊé•ÂàõÂª∫ÊàêÂäü")
                        except OSError as link_err:
                            logger.warn(f"linkÊ®°ÂºèÔºöÁ°¨ÈìæÊé•Â§±Ë¥•ÔºàÂèØËÉΩË∑®Êñá‰ª∂Á≥ªÁªüÔºâÔºåÂ∞ùËØïÂ§çÂà∂Ôºö{str(link_err)}")
                            shutil.copy2(file_path, target_file)
                            transfer_method = "Â§çÂà∂"
                            logger.info(f"linkÊ®°ÂºèÔºöÊñá‰ª∂Â§çÂà∂ÂÆåÊàê")
                        
                        # ÂèëÈÄÅÁÆÄÂåñÈÄöÁü•
                        if self._notify:
                            file_size = target_file.stat().st_size
                            
                            # Ê†ºÂºèÂåñÊñá‰ª∂Â§ßÂ∞è
                            if file_size >= 1024**3:
                                size_str = f"{file_size / (1024**3):.2f}GB"
                            elif file_size >= 1024**2:
                                size_str = f"{file_size / (1024**2):.2f}MB"
                            else:
                                size_str = f"{file_size / 1024:.2f}KB"
                            
                            notify_text = f"üîó {transfer_method} | üíæ {size_str}"
                            
                            self.post_message(
                                mtype=NotificationType.Manual,
                                title=f"‚úÖ ËΩ¨ÁßªÔºö{new_file_name}",
                                text=notify_text
                            )
                            logger.info(f"linkÊ®°ÂºèÔºöÂ∑≤ÂèëÈÄÅÁÆÄÂåñÈÄöÁü•")
                        
                        # Ê∑ªÂä†Âà∞ÊâπÊ¨°Ê±áÊÄª
                        original_dir = relative_path.parent if relative_path.parent != Path('.') else "Ê†πÁõÆÂΩï"
                        target_relative = target_file.relative_to(target)
                        target_dir_display = target_relative.parent if target_relative.parent != Path('.') else "Ê†πÁõÆÂΩï"
                        
                        self.__add_to_batch({
                            'time': datetime.now(),
                            'source_dir': str(original_dir),
                            'target_dir': str(target_dir_display),
                            'source_file': file_path.name,
                            'target_file': new_file_name,
                            'size': file_size,
                            'method': 'link'
                        })
                        
                        logger.info(f"linkÊ®°ÂºèÔºö{file_path.name} Â§ÑÁêÜÊàêÂäüÔºà{transfer_method}Ôºâ")
                        return
                    except Exception as e:
                        logger.error(f"linkÊ®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•Ôºö{str(e)}")
                        logger.error(f"linkÊ®°ÂºèÔºöÈîôËØØËØ¶ÊÉÖ {traceback.format_exc()}")
                        return

                # copyhashÊ®°ÂºèÔºöÁ∫ØÂ§çÂà∂Ê®°ÂºèÔºåË∑≥ËøáËØÜÂà´ÂíåÊï¥ÁêÜÊµÅÁ®ã
                elif transfer_type == "copyhash":
                    logger.info(f"copyhashÊ®°ÂºèÔºöÂºÄÂßãÁ∫ØÂ§çÂà∂Â§ÑÁêÜ {file_path.name}")
                    try:
                        if not target:
                            logger.error(f"copyhashÊ®°ÂºèÔºöÊú™ÈÖçÁΩÆÁõëÊéßÁõÆÂΩï {mon_path} ÁöÑÁõÆÁöÑÁõÆÂΩï")
                            return
                        
                        # ËÆ°ÁÆóÁõ∏ÂØπË∑ØÂæÑ
                        mon_path_obj = Path(mon_path)
                        relative_path = file_path.relative_to(mon_path_obj)
                        logger.info(f"copyhashÊ®°ÂºèÔºöÁõ∏ÂØπË∑ØÂæÑ {relative_path}")
                        
                        # ÁîüÊàêÊñ∞ÁöÑÁõÆÂΩïÂíåÊñá‰ª∂Âêç
                        target_dir, new_file_name = self.__generate_new_paths(relative_path, target, file_path.name)
                        target_file = target_dir / file_path.name
                        logger.info(f"copyhashÊ®°ÂºèÔºöÁõÆÊ†áË∑ØÂæÑ {target_file}")
                        
                        # Á°Æ‰øùÁõÆÊ†áÁõÆÂΩïÂ≠òÂú®
                        target_dir.mkdir(parents=True, exist_ok=True)
                        
                        # Â§çÂà∂Êñá‰ª∂
                        logger.info(f"copyhashÊ®°ÂºèÔºöÂºÄÂßãÂ§çÂà∂Êñá‰ª∂ {file_path} -> {target_file}")
                        shutil.copy2(file_path, target_file)
                        logger.info(f"copyhashÊ®°ÂºèÔºöÊñá‰ª∂Â§çÂà∂ÂÆåÊàê")
                        
                        # Â§ÑÁêÜhash‰øÆÊîπÂíåÈáçÂëΩÂêç
                        if target_file.exists() and target_file.is_file():
                            # ‰ΩøÁî®ÂÖ¨ÂÖ±ÂáΩÊï∞ÁîüÊàêÁöÑÊñá‰ª∂Âêç
                            new_file_path = target_file.parent / new_file_name
                            
                            # ËÆ°ÁÆóÂéüÂßãÊñá‰ª∂hashÔºàÈáçÂëΩÂêçÂâçÔºâ
                            original_size = target_file.stat().st_size
                            hash_md5_original = hashlib.md5()
                            with open(target_file, 'rb') as f:
                                for chunk in iter(lambda: f.read(8192), b""):
                                    hash_md5_original.update(chunk)
                            original_hash = hash_md5_original.hexdigest()
                            logger.info(f"copyhashÊ®°ÂºèÔºöÂéüÂßãÊñá‰ª∂hash={original_hash}")
                            
                            # Âú®Êñá‰ª∂Êú´Â∞æËøΩÂä†ÈöèÊú∫Á©∫ÁôΩÂ≠óÁ¨¶ÊîπÂèòhash
                            whitespace_chars = [' ', '\t', '\n']
                            random_count = random.randint(10, 30)
                            random_whitespaces = ''.join(random.choices(whitespace_chars, k=random_count))
                            logger.info(f"copyhashÊ®°ÂºèÔºöÂáÜÂ§áÂú®Êñá‰ª∂Êú´Â∞æÊ∑ªÂä†{random_count}‰∏™ÈöèÊú∫Á©∫ÁôΩÂ≠óÁ¨¶")
                            
                            with open(target_file, 'ab') as f:
                                f.write(random_whitespaces.encode('utf-8'))
                            new_size = target_file.stat().st_size
                            logger.info(f"copyhashÊ®°ÂºèÔºöÊñá‰ª∂Â§ßÂ∞è‰ªé{original_size}Â≠óËäÇÂ¢ûÂä†Âà∞{new_size}Â≠óËäÇ")
                            
                            # ËÆ°ÁÆó‰øÆÊîπÂêéÁöÑÊñá‰ª∂hash
                            hash_md5_new = hashlib.md5()
                            with open(target_file, 'rb') as f:
                                for chunk in iter(lambda: f.read(8192), b""):
                                    hash_md5_new.update(chunk)
                            new_hash = hash_md5_new.hexdigest()
                            logger.info(f"copyhashÊ®°ÂºèÔºö‰øÆÊîπÂêéÊñá‰ª∂hash={new_hash}")
                            logger.info(f"copyhashÊ®°ÂºèÔºöhashÂ∑≤ÊîπÂèò {original_hash} -> {new_hash}")
                            
                            # ÂÖà‰øÆÊîπhashÔºåÂÜçÈáçÂëΩÂêçÔºàÈÅøÂÖçÊñá‰ª∂ÂêçÂÜ≤Á™ÅÔºâ
                            if target_file != new_file_path:
                                target_file.rename(new_file_path)
                                logger.info(f"copyhashÊ®°ÂºèÔºöÊñá‰ª∂ÈáçÂëΩÂêçÊàêÂäü {target_file.name} -> {new_file_path.name}")
                            logger.info(f"copyhashÊ®°ÂºèÔºöÂ§ÑÁêÜÂÆåÊàê {new_file_path}")
                        
                        # ÂèëÈÄÅÁÆÄÂåñÈÄöÁü•
                        if self._notify:
                            # Ê†ºÂºèÂåñÊñá‰ª∂Â§ßÂ∞è
                            if new_size >= 1024**3:
                                size_str = f"{new_size / (1024**3):.2f}GB"
                            elif new_size >= 1024**2:
                                size_str = f"{new_size / (1024**2):.2f}MB"
                            else:
                                size_str = f"{new_size / 1024:.2f}KB"
                            
                            notify_text = f"üìù Â§çÂà∂+ÊîπHash | üíæ {size_str}"
                            
                            self.post_message(
                                mtype=NotificationType.Manual,
                                title=f"‚úÖ ËΩ¨ÁßªÔºö{new_file_path.name}",
                                text=notify_text
                            )
                            logger.info(f"copyhashÊ®°ÂºèÔºöÂ∑≤ÂèëÈÄÅÁÆÄÂåñÈÄöÁü•")
                        
                        # Ê∑ªÂä†Âà∞ÊâπÊ¨°Ê±áÊÄª
                        original_dir = relative_path.parent if relative_path.parent != Path('.') else "Ê†πÁõÆÂΩï"
                        target_relative = new_file_path.relative_to(target)
                        target_dir_display = target_relative.parent if target_relative.parent != Path('.') else "Ê†πÁõÆÂΩï"
                        
                        self.__add_to_batch({
                            'time': datetime.now(),
                            'source_dir': str(original_dir),
                            'target_dir': str(target_dir_display),
                            'source_file': file_path.name,
                            'target_file': new_file_path.name,
                            'size': new_size,
                            'method': 'copyhash'
                        })
                        
                        logger.info(f"copyhashÊ®°ÂºèÔºö{file_path.name} Â§ÑÁêÜÊàêÂäü")
                        return
                    except Exception as e:
                        logger.error(f"copyhashÊ®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•Ôºö{str(e)}")
                        logger.error(f"copyhashÊ®°ÂºèÔºöÈîôËØØËØ¶ÊÉÖ {traceback.format_exc()}")
                        return
                
                else:
                    # ‰∏çÊîØÊåÅÁöÑËΩ¨ÁßªÊñπÂºè
                    logger.error(f"‰∏çÊîØÊåÅÁöÑËΩ¨ÁßªÊñπÂºèÔºö{transfer_type}Ôºå‰ªÖÊîØÊåÅlinkÂíåcopyhash")
                    return
        
        except Exception as e:
            logger.error("ÁõÆÂΩïÁõëÊéßÂèëÁîüÈîôËØØÔºö%s - %s" % (str(e), traceback.format_exc()))


    def get_state(self) -> bool:
        return self._enabled

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """
        ÂÆö‰πâËøúÁ®ãÊéßÂà∂ÂëΩ‰ª§
        :return: ÂëΩ‰ª§ÂÖ≥ÈîÆÂ≠ó„ÄÅ‰∫ã‰ª∂„ÄÅÊèèËø∞„ÄÅÈôÑÂ∏¶Êï∞ÊçÆ
        """
        return [
            {
                "cmd": "/cloud_link_sync",
                "event": EventType.PluginAction,
                "desc": "‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂêåÊ≠•",
                "category": "",
                "data": {
                    "action": "cloud_link_sync"
                }
            },
            {
                "cmd": "/sync_check",
                "event": EventType.PluginAction,
                "desc": "Ê£ÄÊü•ÂêåÊ≠•Áä∂ÊÄÅ",
                "category": "",
                "data": {
                    "action": "sync_check"
                }
            }
        ]

    def get_api(self) -> List[Dict[str, Any]]:
        return [{
            "path": "/cloud_link_sync",
            "endpoint": self.sync,
            "methods": ["GET"],
            "summary": "‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂêåÊ≠•",
            "description": "‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂêåÊ≠•",
        }]

    def get_service(self) -> List[Dict[str, Any]]:
        """
        Ê≥®ÂÜåÊèí‰ª∂ÂÖ¨ÂÖ±ÊúçÂä°
        [{
            "id": "ÊúçÂä°ID",
            "name": "ÊúçÂä°ÂêçÁß∞",
            "trigger": "Ëß¶ÂèëÂô®Ôºöcron/interval/date/CronTrigger.from_crontab()",
            "func": self.xxx,
            "kwargs": {} # ÂÆöÊó∂Âô®ÂèÇÊï∞
        }]
        """
        if self._enabled and self._cron:
            return [{
                "id": "CloudLinkMonitor",
                "name": "‰∫ëÁõòÂÆûÊó∂ÁõëÊéßÂÖ®ÈáèÂêåÊ≠•ÊúçÂä°",
                "trigger": CronTrigger.from_crontab(self._cron),
                "func": self.sync_all,
                "kwargs": {}
            }]
        return []

    def sync(self) -> schemas.Response:
        """
        APIË∞ÉÁî®ÁõÆÂΩïÂêåÊ≠•
        """
        self.sync_all()
        return schemas.Response(success=True)

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        return [
            {
                'component': 'VForm',
                'content': [
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'enabled',
                                            'label': 'ÂêØÁî®Êèí‰ª∂',
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'notify',
                                            'label': 'ÂèëÈÄÅÈÄöÁü•',
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'onlyonce',
                                            'label': 'Á´ãÂç≥ËøêË°å‰∏ÄÊ¨°',
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSelect',
                                        'props': {
                                            'model': 'transfer_type',
                                            'label': 'ËΩ¨ÁßªÊñπÂºè',
                                            'items': [
                                                {'title': 'Á°¨ÈìæÊé•', 'value': 'link'},
                                                {'title': 'Â§çÂà∂ÊîπHash', 'value': 'copyhash'}
                                            ]
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'cron',
                                            'label': 'ÂÆöÊó∂‰ªªÂä°',
                                            'placeholder': '0 0 * * *'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12
                                },
                                'content': [
                                    {
                                        'component': 'VTextarea',
                                        'props': {
                                            'model': 'monitor_dirs',
                                            'label': 'ÁõëÊéßÁõÆÂΩï',
                                            'rows': 5,
                                            'placeholder': 'ÊØè‰∏ÄË°å‰∏Ä‰∏™ÁõÆÂΩïÔºåÊîØÊåÅ‰ª•‰∏ãÂá†ÁßçÈÖçÁΩÆÊñπÂºèÔºö\n'
                                                           'ÁõëÊéßÁõÆÂΩï:ËΩ¨ÁßªÁõÆÁöÑÁõÆÂΩï\n'
                                                           'ÁõëÊéßÁõÆÂΩï:ËΩ¨ÁßªÁõÆÁöÑÁõÆÂΩï#link\n'
                                                           'ÁõëÊéßÁõÆÂΩï:ËΩ¨ÁßªÁõÆÁöÑÁõÆÂΩï#copyhash\n'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VTextarea',
                                        'props': {
                                            'model': 'exclude_keywords',
                                            'label': 'ÊéíÈô§ÂÖ≥ÈîÆËØç',
                                            'rows': 2,
                                            'placeholder': 'ÊØè‰∏ÄË°å‰∏Ä‰∏™ÂÖ≥ÈîÆËØç'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'linkÊ®°ÂºèÔºöÁ°¨ÈìæÊé•ÔºàÂêåÊñá‰ª∂Á≥ªÁªüÔºâÊàñÂ§çÂà∂ÔºàË∑®Êñá‰ª∂Á≥ªÁªüÔºâ+ÊîπÂêçÔºå‰∏çÊîπhash„ÄÇ\ncopyhashÊ®°ÂºèÔºöÂ§çÂà∂+ÊîπÂêç+Êîπhash„ÄÇ\n‰∏§ÁßçÊ®°ÂºèÈÉΩ‰ºöÊ∑∑Ê∑ÜÁõÆÂΩïÂêçÔºà‰øùÁïô1-2‰∏™Â≠ó+ÁπÅ‰ΩìÂ≠ó+Âπ¥‰ªΩÔºâÂíåÊñá‰ª∂ÂêçÔºàS01E01-1080p.mkvÊàñ1080p.mkvÔºâÔºåSeasonÁõÆÂΩï‰∏çÊîπ„ÄÇ'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                ]
            }
        ], {
            "enabled": False,
            "notify": False,
            "onlyonce": False,
            "transfer_type": "link",
            "monitor_dirs": "",
            "exclude_keywords": "",
            "cron": "0 0 * * *",
            "size": 0
        }

    def get_page(self) -> List[dict]:
        pass

    def stop_service(self):
        """
        ÈÄÄÂá∫Êèí‰ª∂
        """
        if self._observer:
            for observer in self._observer:
                try:
                    observer.stop()
                    observer.join()
                except Exception as e:
                    print(str(e))
        self._observer = []
        if self._scheduler:
            self._scheduler.remove_all_jobs()
            if self._scheduler.running:
                self._event.set()
                self._scheduler.shutdown()
                self._event.clear()
            self._scheduler = None
