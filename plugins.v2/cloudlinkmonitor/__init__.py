from datetime import datetime
import hashlib
import random
import re
import shutil
import threading
import traceback
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional

import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
from watchdog.observers.polling import PollingObserver

from app import schemas
from app.chain.media import MediaChain
from app.chain.storage import StorageChain
from app.chain.tmdb import TmdbChain
from app.chain.transfer import TransferChain
from app.core.config import settings
from app.core.context import MediaInfo
from app.core.event import eventmanager, Event
from app.core.metainfo import MetaInfoPath
from app.db.downloadhistory_oper import DownloadHistoryOper
from app.db.transferhistory_oper import TransferHistoryOper
from app.helper.directory import DirectoryHelper
from app.log import logger
from app.modules.filemanager import FileManagerModule
from app.plugins import _PluginBase
from app.schemas import NotificationType, TransferInfo, TransferDirectoryConf
from app.schemas.types import EventType, MediaType, SystemConfigKey
from app.utils.string import StringUtils
from app.utils.system import SystemUtils

lock = threading.Lock()


class FileMonitorHandler(FileSystemEventHandler):
    """
    ç›®å½•ç›‘æ§å“åº”ç±»
    """

    def __init__(self, monpath: str, sync: Any, **kwargs):
        super(FileMonitorHandler, self).__init__(**kwargs)
        self._watch_path = monpath
        self.sync = sync

    def on_created(self, event):
        self.sync.event_handler(event=event, text="åˆ›å»º",
                                mon_path=self._watch_path, event_path=event.src_path)

    def on_moved(self, event):
        self.sync.event_handler(event=event, text="ç§»åŠ¨",
                                mon_path=self._watch_path, event_path=event.dest_path)


class CloudLinkMonitor(_PluginBase):
    # æ’ä»¶åç§°
    plugin_name = "ç›‘æ§è½¬ç§»æ–‡ä»¶"
    # æ’ä»¶æè¿°
    plugin_desc = "ç›‘æ§ç›®å½•æ–‡ä»¶å˜åŒ–ï¼Œæ”¯æŒç¡¬é“¾æ¥å’Œå¤åˆ¶æ”¹Hashï¼Œè‡ªåŠ¨æ··æ·†ç›®å½•å’Œæ–‡ä»¶åï¼Œæ‰¹æ¬¡æ±‡æ€»é€šçŸ¥ã€‚"
    # æ’ä»¶å›¾æ ‡
    plugin_icon = "Linkease_A.png"
    # æ’ä»¶ç‰ˆæœ¬
    plugin_version = "3.3.1"
    # æ’ä»¶ä½œè€…
    plugin_author = "thsrite"
    # ä½œè€…ä¸»é¡µ
    author_url = "https://github.com/thsrite"
    # æ’ä»¶é…ç½®é¡¹IDå‰ç¼€
    plugin_config_prefix = "cloudlinkmonitor_"
    # åŠ è½½é¡ºåº
    plugin_order = 4
    # å¯ä½¿ç”¨çš„ç”¨æˆ·çº§åˆ«
    auth_level = 1

    # ç§æœ‰å±æ€§
    _scheduler = None
    transferhis = None
    downloadhis = None
    transferchian = None
    tmdbchain = None
    storagechain = None
    _observer = []
    _enabled = False
    _notify = False
    _onlyonce = False
    _cron = None
    filetransfer = None
    mediaChain = None
    _size = 0
    _monitor_dirs = ""
    _exclude_keywords = ""
    _transfer_type = "link"
    # å­˜å‚¨æºç›®å½•ä¸ç›®çš„ç›®å½•å…³ç³»
    _dirconf: Dict[str, Optional[Path]] = {}
    # å­˜å‚¨æºç›®å½•è½¬ç§»æ–¹å¼
    _transferconf: Dict[str, Optional[str]] = {}
    # é€€å‡ºäº‹ä»¶
    _event = threading.Event()
    # æ‰¹æ¬¡æ±‡æ€»ç›¸å…³
    _batch_files = []  # æ‰¹æ¬¡å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    _last_process_time = None  # æœ€åå¤„ç†æ—¶é—´
    _summary_timer = None  # æ±‡æ€»å®šæ—¶å™¨
    _batch_lock = threading.Lock()  # æ‰¹æ¬¡æ•°æ®é”

    def init_plugin(self, config: dict = None):
        self.transferhis = TransferHistoryOper()
        self.downloadhis = DownloadHistoryOper()
        self.transferchian = TransferChain()
        self.tmdbchain = TmdbChain()
        self.mediaChain = MediaChain()
        self.storagechain = StorageChain()
        self.filetransfer = FileManagerModule()
        # æ¸…ç©ºé…ç½®
        self._dirconf = {}
        self._transferconf = {}

        # è¯»å–é…ç½®
        if config:
            self._enabled = config.get("enabled")
            self._notify = config.get("notify")
            self._onlyonce = config.get("onlyonce")
            self._transfer_type = config.get("transfer_type") or "link"
            self._monitor_dirs = config.get("monitor_dirs") or ""
            self._exclude_keywords = config.get("exclude_keywords") or ""
            self._cron = config.get("cron")
            self._size = config.get("size") or 0

        # åœæ­¢ç°æœ‰ä»»åŠ¡
        self.stop_service()

        if self._enabled or self._onlyonce:
            # å®šæ—¶æœåŠ¡ç®¡ç†å™¨
            self._scheduler = BackgroundScheduler(timezone=settings.TZ)

            # è¯»å–ç›®å½•é…ç½®
            monitor_dirs = self._monitor_dirs.split("\n")
            if not monitor_dirs:
                return
            for mon_path in monitor_dirs:
                # æ ¼å¼æºç›®å½•:ç›®çš„ç›®å½•
                if not mon_path:
                    continue

                # è‡ªå®šä¹‰è½¬ç§»æ–¹å¼ï¼ˆæ”¯æŒlinkå’Œcopyhashï¼‰
                _transfer_type = self._transfer_type
                if mon_path.count("#") == 1:
                    _transfer_type = mon_path.split("#")[1]
                    mon_path = mon_path.split("#")[0]

                # å­˜å‚¨ç›®çš„ç›®å½•
                if SystemUtils.is_windows():
                    if mon_path.count(":") > 1:
                        paths = [mon_path.split(":")[0] + ":" + mon_path.split(":")[1],
                                 mon_path.split(":")[2] + ":" + mon_path.split(":")[3]]
                    else:
                        paths = [mon_path]
                else:
                    paths = mon_path.split(":")

                # ç›®çš„ç›®å½•
                target_path = None
                if len(paths) > 1:
                    mon_path = paths[0]
                    target_path = Path(paths[1])
                    self._dirconf[mon_path] = target_path
                else:
                    self._dirconf[mon_path] = None

                # è½¬ç§»æ–¹å¼
                self._transferconf[mon_path] = _transfer_type

                # å¯ç”¨ç›®å½•ç›‘æ§
                if self._enabled:
                    # æ£€æŸ¥åª’ä½“åº“ç›®å½•æ˜¯ä¸æ˜¯ä¸‹è½½ç›®å½•çš„å­ç›®å½•
                    try:
                        if target_path and target_path.is_relative_to(Path(mon_path)):
                            logger.warn(f"{target_path} æ˜¯ç›‘æ§ç›®å½• {mon_path} çš„å­ç›®å½•ï¼Œæ— æ³•ç›‘æ§")
                            self.systemmessage.put(f"{target_path} æ˜¯ä¸‹è½½ç›®å½• {mon_path} çš„å­ç›®å½•ï¼Œæ— æ³•ç›‘æ§")
                            continue
                    except Exception as e:
                        logger.debug(str(e))
                        pass

                    try:
                        # ä½¿ç”¨é»˜è®¤Observer
                        observer = Observer(timeout=10)
                        self._observer.append(observer)
                        observer.schedule(FileMonitorHandler(mon_path, self), path=mon_path, recursive=True)
                        observer.daemon = True
                        observer.start()
                        logger.info(f"{mon_path} çš„äº‘ç›˜å®æ—¶ç›‘æ§æœåŠ¡å¯åŠ¨")
                    except Exception as e:
                        err_msg = str(e)
                        if "inotify" in err_msg and "reached" in err_msg:
                            logger.warn(
                                f"äº‘ç›˜å®æ—¶ç›‘æ§æœåŠ¡å¯åŠ¨å‡ºç°å¼‚å¸¸ï¼š{err_msg}ï¼Œè¯·åœ¨å®¿ä¸»æœºä¸Šï¼ˆä¸æ˜¯dockerå®¹å™¨å†…ï¼‰æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¹¶é‡å¯ï¼š"
                                + """
                                     echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf
                                     echo fs.inotify.max_user_instances=524288 | sudo tee -a /etc/sysctl.conf
                                     sudo sysctl -p
                                     """)
                        else:
                            logger.error(f"{mon_path} å¯åŠ¨ç›®äº‘ç›˜å®æ—¶ç›‘æ§å¤±è´¥ï¼š{err_msg}")
                        self.systemmessage.put(f"{mon_path} å¯åŠ¨äº‘ç›˜å®æ—¶ç›‘æ§å¤±è´¥ï¼š{err_msg}")

            # è¿è¡Œä¸€æ¬¡å®šæ—¶æœåŠ¡
            if self._onlyonce:
                logger.info("äº‘ç›˜å®æ—¶ç›‘æ§æœåŠ¡å¯åŠ¨ï¼Œç«‹å³è¿è¡Œä¸€æ¬¡")
                self._scheduler.add_job(name="äº‘ç›˜å®æ—¶ç›‘æ§",
                                        func=self.sync_all, trigger='date',
                                        run_date=datetime.datetime.now(
                                            tz=pytz.timezone(settings.TZ)) + datetime.timedelta(seconds=3)
                                        )
                # å…³é—­ä¸€æ¬¡æ€§å¼€å…³
                self._onlyonce = False
                # ä¿å­˜é…ç½®
                self.__update_config()

            # å¯åŠ¨å®šæ—¶æœåŠ¡
            if self._scheduler.get_jobs():
                self._scheduler.print_jobs()
                self._scheduler.start()

    def __update_config(self):
        """
        æ›´æ–°é…ç½®
        """
        self.update_config({
            "enabled": self._enabled,
            "notify": self._notify,
            "onlyonce": self._onlyonce,
            "transfer_type": self._transfer_type,
            "monitor_dirs": self._monitor_dirs,
            "exclude_keywords": self._exclude_keywords,
            "cron": self._cron,
            "size": self._size,
        })

    @eventmanager.register(EventType.PluginAction)
    def remote_sync(self, event: Event):
        """
        è¿œç¨‹å…¨é‡åŒæ­¥
        """
        if event:
            event_data = event.event_data
            if not event_data or event_data.get("action") != "cloud_link_sync":
                return
            self.post_message(channel=event.event_data.get("channel"),
                              title="å¼€å§‹åŒæ­¥äº‘ç›˜å®æ—¶ç›‘æ§ç›®å½• ...",
                              userid=event.event_data.get("user"))
        self.sync_all()
        if event:
            self.post_message(channel=event.event_data.get("channel"),
                              title="äº‘ç›˜å®æ—¶ç›‘æ§ç›®å½•åŒæ­¥å®Œæˆï¼", userid=event.event_data.get("user"))

    def sync_all(self):
        """
        ç«‹å³è¿è¡Œä¸€æ¬¡ï¼Œå…¨é‡åŒæ­¥ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶
        """
        logger.info("å¼€å§‹å…¨é‡åŒæ­¥äº‘ç›˜å®æ—¶ç›‘æ§ç›®å½• ...")
        # éå†æ‰€æœ‰ç›‘æ§ç›®å½•
        for mon_path in self._dirconf.keys():
            logger.info(f"å¼€å§‹å¤„ç†ç›‘æ§ç›®å½• {mon_path} ...")
            list_files = SystemUtils.list_files(Path(mon_path), settings.RMT_MEDIAEXT)
            logger.info(f"ç›‘æ§ç›®å½• {mon_path} å…±å‘ç° {len(list_files)} ä¸ªæ–‡ä»¶")
            # éå†ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶
            for file_path in list_files:
                logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶ {file_path} ...")
                self.__handle_file(event_path=str(file_path), mon_path=mon_path)
        logger.info("å…¨é‡åŒæ­¥äº‘ç›˜å®æ—¶ç›‘æ§ç›®å½•å®Œæˆï¼")

    def event_handler(self, event, mon_path: str, text: str, event_path: str):
        """
        å¤„ç†æ–‡ä»¶å˜åŒ–
        :param event: äº‹ä»¶
        :param mon_path: ç›‘æ§ç›®å½•
        :param text: äº‹ä»¶æè¿°
        :param event_path: äº‹ä»¶æ–‡ä»¶è·¯å¾„
        """
        if not event.is_directory:
            # æ–‡ä»¶å‘ç”Ÿå˜åŒ–
            logger.debug("æ–‡ä»¶%sï¼š%s" % (text, event_path))
            self.__handle_file(event_path=event_path, mon_path=mon_path)
    
    def __add_to_batch(self, file_info: dict):
        """
        æ·»åŠ æ–‡ä»¶åˆ°æ‰¹æ¬¡æ±‡æ€»
        :param file_info: æ–‡ä»¶å¤„ç†ä¿¡æ¯
        """
        with self._batch_lock:
            self._batch_files.append(file_info)
            self._last_process_time = datetime.now()
            
            # é‡ç½®æ±‡æ€»å®šæ—¶å™¨
            if self._summary_timer:
                self._summary_timer.cancel()
            
            # 30ç§’åæ£€æŸ¥æ˜¯å¦å‘é€æ±‡æ€»
            self._summary_timer = threading.Timer(30.0, self.__check_and_send_summary)
            self._summary_timer.daemon = True
            self._summary_timer.start()
    
    def __check_and_send_summary(self):
        """
        æ£€æŸ¥å¹¶å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥
        """
        with self._batch_lock:
            if not self._batch_files:
                return
            
            # æ£€æŸ¥æ˜¯å¦30ç§’å†…æ— æ–°æ–‡ä»¶
            if self._last_process_time and (datetime.now() - self._last_process_time).total_seconds() >= 30:
                self.__send_batch_summary()
    
    def __send_batch_summary(self):
        """
        å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥
        """
        if not self._batch_files:
            return
        
        try:
            # ç»Ÿè®¡ä¿¡æ¯
            total_files = len(self._batch_files)
            total_size = sum(f.get('size', 0) for f in self._batch_files)
            
            # è®¡ç®—ç”¨æ—¶
            start_time = self._batch_files[0].get('time')
            end_time = self._batch_files[-1].get('time')
            if start_time and end_time:
                duration = (end_time - start_time).total_seconds()
                duration_str = f"{int(duration // 60)}åˆ†{int(duration % 60)}ç§’" if duration >= 60 else f"{int(duration)}ç§’"
            else:
                duration_str = "æœªçŸ¥"
            
            # æŒ‰ç›®å½•åˆ†ç»„ç»Ÿè®¡
            dir_stats = {}
            for f in self._batch_files:
                source_dir = f.get('source_dir', 'æœªçŸ¥')
                target_dir = f.get('target_dir', 'æœªçŸ¥')
                key = f"{source_dir}â†’{target_dir}"
                
                if key not in dir_stats:
                    dir_stats[key] = {
                        'source': source_dir,
                        'target': target_dir,
                        'count': 0,
                        'size': 0
                    }
                dir_stats[key]['count'] += 1
                dir_stats[key]['size'] += f.get('size', 0)
            
            # æ„å»ºç›®å½•æ±‡æ€»æ–‡æœ¬
            dir_summary_lines = []
            for stats in dir_stats.values():
                size_gb = stats['size'] / (1024**3)
                dir_summary_lines.append(
                    f"  ğŸ“‚ {stats['source']} ({stats['count']}ä¸ª | {size_gb:.1f}GB)\n"
                    f"  â†“\n"
                    f"  ğŸ“‚ {stats['target']}\n"
                )
            dir_summary = "\n".join(dir_summary_lines)
            
            # æ ¼å¼åŒ–æ€»å¤§å°
            if total_size >= 1024**3:
                size_str = f"{total_size / (1024**3):.2f} GB"
            elif total_size >= 1024**2:
                size_str = f"{total_size / (1024**2):.2f} MB"
            else:
                size_str = f"{total_size / 1024:.2f} KB"
            
            # å‘é€é€šçŸ¥
            notify_text = (
                f"ğŸ“Š ç»Ÿè®¡ï¼š{total_files} ä¸ªæ–‡ä»¶ | {size_str}\n"
                f"â±ï¸ ç”¨æ—¶ï¼š{duration_str}\n"
                f"ğŸ”— è½¬ç§»æ–¹å¼ï¼š{self._batch_files[0].get('method', 'æœªçŸ¥')}\n\n"
                f"ğŸ“‚ ç›®å½•æ±‡æ€»ï¼š\n{dir_summary}"
            )
            
            self.post_message(
                mtype=NotificationType.Manual,
                title="âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼",
                text=notify_text
            )
            
            logger.info(f"æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥å·²å‘é€ï¼šå…±å¤„ç† {total_files} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"å‘é€æ‰¹æ¬¡æ±‡æ€»é€šçŸ¥å¤±è´¥ï¼š{str(e)}")
        finally:
            # æ¸…ç©ºæ‰¹æ¬¡åˆ—è¡¨
            self._batch_files = []
            self._last_process_time = None
    
    def __generate_new_paths(self, relative_path: Path, target: Path, file_name: str):
        """
        ç”Ÿæˆæ··æ·†åçš„ç›®å½•å’Œæ–‡ä»¶å
        :param relative_path: ç›¸å¯¹è·¯å¾„
        :param target: ç›®æ ‡æ ¹ç›®å½•
        :param file_name: åŸå§‹æ–‡ä»¶å
        :return: (ç›®æ ‡ç›®å½•, æ–°æ–‡ä»¶å)
        """
        # å¤„ç†ç›®å½•åï¼šä¿ç•™1-2ä¸ªåŸåå­—+MD5ç”Ÿæˆçš„ç¹ä½“å­—+ä¿ç•™(å¹´ä»½)
        if relative_path.parent != Path('.'):
            parent_parts = list(relative_path.parent.parts)
            new_parent_parts = []
            
            for i, dir_name in enumerate(parent_parts):
                # è·³è¿‡Seasonç›®å½•ï¼ˆä¸æ”¹ï¼‰
                if re.match(r'^Season\s+\d+$', dir_name, re.IGNORECASE):
                    new_parent_parts.append(dir_name)
                    logger.info(f"ä¿ç•™Seasonç›®å½•: {dir_name}")
                    continue
                
                # æå–å¹´ä»½ï¼ˆå¦‚æœæœ‰ï¼‰
                year_match = re.search(r'\((\d{4})\)$', dir_name)
                year_suffix = f" ({year_match.group(1)})" if year_match else ""
                
                # å»æ‰å¹´ä»½åçš„ç›®å½•å
                dir_name_without_year = re.sub(r'\s*\(\d{4}\)$', '', dir_name)
                
                # ä½¿ç”¨MD5ç¡®ä¿ç¡®å®šæ€§
                hash_obj = hashlib.md5(dir_name.encode('utf-8'))
                hash_int = int(hash_obj.hexdigest(), 16)
                
                # ç¹ä½“å­—åº“
                traditional_chars = ['ç¹', 'é«”', 'å­—', 'éš¨', 'æ©Ÿ', 'è®Š', 'æ›', 'æª”', 'æ¡ˆ', 'é›œ', 'æ¹Š', 'æ¸¬', 'è©¦', 'é›»', 'å½±', 'è¦–', 'é »', 'åŠ‡', 'é›†', 'ç¯€', 'ç›®', 'è–', 'éˆ', 'é­‚', 'é¬¼', 'ç¥']
                
                # ä¿ç•™å‰1-2ä¸ªå­—ï¼ˆæ ¹æ®hashç¡®å®šä¿ç•™å‡ ä¸ªï¼‰
                keep_count = 1 if (hash_int % 2 == 0) else 2
                if len(dir_name_without_year) < keep_count:
                    keep_count = len(dir_name_without_year)
                
                prefix = dir_name_without_year[:keep_count] if dir_name_without_year else ""
                
                # ç”Ÿæˆ3-5ä¸ªç¹ä½“å­—
                char_count = (hash_int % 3) + 3  # 3-5ä¸ªå­—ç¬¦
                selected_chars = []
                for j in range(char_count):
                    idx = (hash_int >> (j * 5)) % len(traditional_chars)
                    selected_chars.append(traditional_chars[idx])
                random_chars = ''.join(selected_chars)
                
                # æ„å»ºæ–°ç›®å½•åï¼šå‰ç¼€ + ç¹ä½“å­— + å¹´ä»½
                new_dir = prefix + random_chars + year_suffix
                new_parent_parts.append(new_dir)
                logger.info(f"ç›®å½•åæ··æ·†: {dir_name} -> {new_dir}")
            
            target_dir = target / Path(*new_parent_parts) if new_parent_parts else target
        else:
            target_dir = target
        
        # å¤„ç†æ–‡ä»¶åï¼šæå–S01E01å’Œè§†é¢‘æ ¼å¼
        file_stem = Path(file_name).stem
        file_suffix = Path(file_name).suffix
        
        # æå–å­£é›†å·ï¼ˆS01E01æ ¼å¼ï¼‰
        season_episode = re.search(r'[Ss](\d+)[Ee](\d+)', file_stem)
        
        # æå–è§†é¢‘æ ¼å¼ä¿¡æ¯ï¼ˆ1080p, 4K, 2160pç­‰ï¼‰
        video_format = re.search(r'(\d{3,4}[pP]|[248][kK]|[hH][dD]|[uU][hH][dD])', file_stem)
        
        if season_episode:
            # ç”µè§†å‰§ï¼šS01E01-1080p.mkv
            new_stem = f"S{season_episode.group(1)}E{season_episode.group(2)}"
            if video_format:
                new_stem += f"-{video_format.group(1)}"
            logger.info(f"ç”µè§†å‰§æ–‡ä»¶å: {new_stem}")
        elif video_format:
            # ç”µå½±ï¼š1080p.mkv
            new_stem = video_format.group(1)
            logger.info(f"ç”µå½±æ–‡ä»¶å: {new_stem}")
        else:
            # æ²¡æœ‰è¯†åˆ«åˆ°æ ¼å¼ï¼Œä½¿ç”¨movieä½œä¸ºå‰ç¼€
            new_stem = "movie"
            logger.info(f"æœªè¯†åˆ«åˆ°æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶å: {new_stem}")
        
        new_file_name = f"{new_stem}{file_suffix}"
        
        return target_dir, new_file_name

    def __handle_file(self, event_path: str, mon_path: str):
        """
        åŒæ­¥ä¸€ä¸ªæ–‡ä»¶
        :param event_path: äº‹ä»¶æ–‡ä»¶è·¯å¾„
        :param mon_path: ç›‘æ§ç›®å½•
        """
        file_path = Path(event_path)
        try:
            if not file_path.exists():
                return
            # å…¨ç¨‹åŠ é”
            with lock:
                # æŸ¥è¯¢è½¬ç§»æ–¹å¼ï¼ˆæå‰è·å–ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦è·³è¿‡å†å²æ£€æŸ¥ï¼‰
                transfer_type = self._transferconf.get(mon_path)
                
                # copyhashæ¨¡å¼ä¸æ£€æŸ¥å†å²è®°å½•ï¼Œå…è®¸é‡å¤å¤„ç†
                if transfer_type != "copyhash":
                    transfer_history = self.transferhis.get_by_src(event_path)
                    if transfer_history:
                        logger.info("æ–‡ä»¶å·²å¤„ç†è¿‡ï¼š%s" % event_path)
                        return

                # å›æ”¶ç«™åŠéšè—çš„æ–‡ä»¶ä¸å¤„ç†
                if event_path.find('/@Recycle/') != -1 \
                        or event_path.find('/#recycle/') != -1 \
                        or event_path.find('/.') != -1 \
                        or event_path.find('/@eaDir') != -1:
                    logger.debug(f"{event_path} æ˜¯å›æ”¶ç«™æˆ–éšè—çš„æ–‡ä»¶")
                    return

                # å‘½ä¸­è¿‡æ»¤å…³é”®å­—ä¸å¤„ç†
                if self._exclude_keywords:
                    for keyword in self._exclude_keywords.split("\n"):
                        if keyword and re.findall(keyword, event_path):
                            logger.info(f"{event_path} å‘½ä¸­è¿‡æ»¤å…³é”®å­— {keyword}ï¼Œä¸å¤„ç†")
                            return

                # æ•´ç†å±è”½è¯ä¸å¤„ç†
                transfer_exclude_words = self.systemconfig.get(SystemConfigKey.TransferExcludeWords)
                if transfer_exclude_words:
                    for keyword in transfer_exclude_words:
                        if not keyword:
                            continue
                        if keyword and re.search(r"%s" % keyword, event_path, re.IGNORECASE):
                            logger.info(f"{event_path} å‘½ä¸­æ•´ç†å±è”½è¯ {keyword}ï¼Œä¸å¤„ç†")
                            return

                # ä¸æ˜¯åª’ä½“æ–‡ä»¶ä¸å¤„ç†
                if file_path.suffix not in settings.RMT_MEDIAEXT:
                    logger.debug(f"{event_path} ä¸æ˜¯åª’ä½“æ–‡ä»¶")
                    return

                # åˆ¤æ–­æ˜¯ä¸æ˜¯è“å…‰ç›®å½•
                if re.search(r"BDMV[/\\]STREAM", event_path, re.IGNORECASE):
                    # æˆªå–BDMVå‰é¢çš„è·¯å¾„
                    blurray_dir = event_path[:event_path.find("BDMV")]
                    file_path = Path(blurray_dir)
                    logger.info(f"{event_path} æ˜¯è“å…‰ç›®å½•ï¼Œæ›´æ­£æ–‡ä»¶è·¯å¾„ä¸ºï¼š{str(file_path)}")
                    # æŸ¥è¯¢å†å²è®°å½•ï¼Œå·²è½¬ç§»çš„ä¸å¤„ç†
                    if self.transferhis.get_by_src(str(file_path)):
                        logger.info(f"{file_path} å·²æ•´ç†è¿‡")
                        return

                # å…ƒæ•°æ®
                file_meta = MetaInfoPath(file_path)
                if not file_meta.name:
                    logger.error(f"{file_path.name} æ— æ³•è¯†åˆ«æœ‰æ•ˆä¿¡æ¯")
                    return

                # åˆ¤æ–­æ–‡ä»¶å¤§å°
                if self._size and float(self._size) > 0 and file_path.stat().st_size < float(self._size) * 1024 ** 3:
                    logger.info(f"{file_path} æ–‡ä»¶å¤§å°å°äºç›‘æ§æ–‡ä»¶å¤§å°ï¼Œä¸å¤„ç†")
                    return

                # æŸ¥è¯¢è½¬ç§»ç›®çš„ç›®å½•
                target: Path = self._dirconf.get(mon_path)

                # linkæ¨¡å¼ï¼šç¡¬é“¾æ¥+æ”¹åï¼ˆä¸æ”¹hashï¼‰
                if transfer_type == "link":
                    logger.info(f"linkæ¨¡å¼ï¼šå¼€å§‹å¤„ç† {file_path.name}")
                    try:
                        if not target:
                            logger.error(f"linkæ¨¡å¼ï¼šæœªé…ç½®ç›‘æ§ç›®å½• {mon_path} çš„ç›®çš„ç›®å½•")
                            return
                        
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        mon_path_obj = Path(mon_path)
                        relative_path = file_path.relative_to(mon_path_obj)
                        logger.info(f"linkæ¨¡å¼ï¼šç›¸å¯¹è·¯å¾„ {relative_path}")
                        
                        # ç”Ÿæˆæ–°çš„ç›®å½•å’Œæ–‡ä»¶å
                        target_dir, new_file_name = self.__generate_new_paths(relative_path, target, file_path.name)
                        target_file = target_dir / new_file_name
                        logger.info(f"linkæ¨¡å¼ï¼šç›®æ ‡è·¯å¾„ {target_file}")
                        
                        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                        target_dir.mkdir(parents=True, exist_ok=True)
                        
                        # å°è¯•ç¡¬é“¾æ¥ï¼Œå¤±è´¥åˆ™å¤åˆ¶
                        try:
                            logger.info(f"linkæ¨¡å¼ï¼šå°è¯•åˆ›å»ºç¡¬é“¾æ¥ {file_path} -> {target_file}")
                            import os
                            os.link(str(file_path), str(target_file))
                            transfer_method = "ç¡¬é“¾æ¥"
                            logger.info(f"linkæ¨¡å¼ï¼šç¡¬é“¾æ¥åˆ›å»ºæˆåŠŸ")
                        except OSError as link_err:
                            logger.warn(f"linkæ¨¡å¼ï¼šç¡¬é“¾æ¥å¤±è´¥ï¼ˆå¯èƒ½è·¨æ–‡ä»¶ç³»ç»Ÿï¼‰ï¼Œå°è¯•å¤åˆ¶ï¼š{str(link_err)}")
                            shutil.copy2(file_path, target_file)
                            transfer_method = "å¤åˆ¶"
                            logger.info(f"linkæ¨¡å¼ï¼šæ–‡ä»¶å¤åˆ¶å®Œæˆ")
                        
                        # å‘é€ç®€åŒ–é€šçŸ¥
                        if self._notify:
                            file_size = target_file.stat().st_size
                            
                            # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                            if file_size >= 1024**3:
                                size_str = f"{file_size / (1024**3):.2f}GB"
                            elif file_size >= 1024**2:
                                size_str = f"{file_size / (1024**2):.2f}MB"
                            else:
                                size_str = f"{file_size / 1024:.2f}KB"
                            
                            notify_text = f"ğŸ”— {transfer_method} | ğŸ’¾ {size_str}"
                            
                            self.post_message(
                                mtype=NotificationType.Manual,
                                title=f"âœ… è½¬ç§»ï¼š{new_file_name}",
                                text=notify_text
                            )
                            logger.info(f"linkæ¨¡å¼ï¼šå·²å‘é€ç®€åŒ–é€šçŸ¥")
                        
                        # æ·»åŠ åˆ°æ‰¹æ¬¡æ±‡æ€»
                        original_dir = relative_path.parent if relative_path.parent != Path('.') else "æ ¹ç›®å½•"
                        target_relative = target_file.relative_to(target)
                        target_dir_display = target_relative.parent if target_relative.parent != Path('.') else "æ ¹ç›®å½•"
                        
                        self.__add_to_batch({
                            'time': datetime.now(),
                            'source_dir': str(original_dir),
                            'target_dir': str(target_dir_display),
                            'source_file': file_path.name,
                            'target_file': new_file_name,
                            'size': file_size,
                            'method': 'link'
                        })
                        
                        logger.info(f"linkæ¨¡å¼ï¼š{file_path.name} å¤„ç†æˆåŠŸï¼ˆ{transfer_method}ï¼‰")
                        return
                    except Exception as e:
                        logger.error(f"linkæ¨¡å¼å¤„ç†å¤±è´¥ï¼š{str(e)}")
                        logger.error(f"linkæ¨¡å¼ï¼šé”™è¯¯è¯¦æƒ… {traceback.format_exc()}")
                        return

                # copyhashæ¨¡å¼ï¼šçº¯å¤åˆ¶æ¨¡å¼ï¼Œè·³è¿‡è¯†åˆ«å’Œæ•´ç†æµç¨‹
                elif transfer_type == "copyhash":
                    logger.info(f"copyhashæ¨¡å¼ï¼šå¼€å§‹çº¯å¤åˆ¶å¤„ç† {file_path.name}")
                    try:
                        if not target:
                            logger.error(f"copyhashæ¨¡å¼ï¼šæœªé…ç½®ç›‘æ§ç›®å½• {mon_path} çš„ç›®çš„ç›®å½•")
                            return
                        
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        mon_path_obj = Path(mon_path)
                        relative_path = file_path.relative_to(mon_path_obj)
                        logger.info(f"copyhashæ¨¡å¼ï¼šç›¸å¯¹è·¯å¾„ {relative_path}")
                        
                        # ç”Ÿæˆæ–°çš„ç›®å½•å’Œæ–‡ä»¶å
                        target_dir, new_file_name = self.__generate_new_paths(relative_path, target, file_path.name)
                        target_file = target_dir / file_path.name
                        logger.info(f"copyhashæ¨¡å¼ï¼šç›®æ ‡è·¯å¾„ {target_file}")
                        
                        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                        target_dir.mkdir(parents=True, exist_ok=True)
                        
                        # å¤åˆ¶æ–‡ä»¶
                        logger.info(f"copyhashæ¨¡å¼ï¼šå¼€å§‹å¤åˆ¶æ–‡ä»¶ {file_path} -> {target_file}")
                        shutil.copy2(file_path, target_file)
                        logger.info(f"copyhashæ¨¡å¼ï¼šæ–‡ä»¶å¤åˆ¶å®Œæˆ")
                        
                        # å¤„ç†hashä¿®æ”¹å’Œé‡å‘½å
                        if target_file.exists() and target_file.is_file():
                            # ä½¿ç”¨å…¬å…±å‡½æ•°ç”Ÿæˆçš„æ–‡ä»¶å
                            new_file_path = target_file.parent / new_file_name
                            
                            # è®¡ç®—åŸå§‹æ–‡ä»¶hashï¼ˆé‡å‘½åå‰ï¼‰
                            original_size = target_file.stat().st_size
                            hash_md5_original = hashlib.md5()
                            with open(target_file, 'rb') as f:
                                for chunk in iter(lambda: f.read(8192), b""):
                                    hash_md5_original.update(chunk)
                            original_hash = hash_md5_original.hexdigest()
                            logger.info(f"copyhashæ¨¡å¼ï¼šåŸå§‹æ–‡ä»¶hash={original_hash}")
                            
                            # åœ¨æ–‡ä»¶æœ«å°¾è¿½åŠ éšæœºç©ºç™½å­—ç¬¦æ”¹å˜hash
                            whitespace_chars = [' ', '\t', '\n']
                            random_count = random.randint(10, 30)
                            random_whitespaces = ''.join(random.choices(whitespace_chars, k=random_count))
                            logger.info(f"copyhashæ¨¡å¼ï¼šå‡†å¤‡åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ {random_count}ä¸ªéšæœºç©ºç™½å­—ç¬¦")
                            
                            with open(target_file, 'ab') as f:
                                f.write(random_whitespaces.encode('utf-8'))
                            new_size = target_file.stat().st_size
                            logger.info(f"copyhashæ¨¡å¼ï¼šæ–‡ä»¶å¤§å°ä»{original_size}å­—èŠ‚å¢åŠ åˆ°{new_size}å­—èŠ‚")
                            
                            # è®¡ç®—ä¿®æ”¹åçš„æ–‡ä»¶hash
                            hash_md5_new = hashlib.md5()
                            with open(target_file, 'rb') as f:
                                for chunk in iter(lambda: f.read(8192), b""):
                                    hash_md5_new.update(chunk)
                            new_hash = hash_md5_new.hexdigest()
                            logger.info(f"copyhashæ¨¡å¼ï¼šä¿®æ”¹åæ–‡ä»¶hash={new_hash}")
                            logger.info(f"copyhashæ¨¡å¼ï¼šhashå·²æ”¹å˜ {original_hash} -> {new_hash}")
                            
                            # å…ˆä¿®æ”¹hashï¼Œå†é‡å‘½åï¼ˆé¿å…æ–‡ä»¶åå†²çªï¼‰
                            if target_file != new_file_path:
                                target_file.rename(new_file_path)
                                logger.info(f"copyhashæ¨¡å¼ï¼šæ–‡ä»¶é‡å‘½åæˆåŠŸ {target_file.name} -> {new_file_path.name}")
                            logger.info(f"copyhashæ¨¡å¼ï¼šå¤„ç†å®Œæˆ {new_file_path}")
                        
                        # å‘é€ç®€åŒ–é€šçŸ¥
                        if self._notify:
                            # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                            if new_size >= 1024**3:
                                size_str = f"{new_size / (1024**3):.2f}GB"
                            elif new_size >= 1024**2:
                                size_str = f"{new_size / (1024**2):.2f}MB"
                            else:
                                size_str = f"{new_size / 1024:.2f}KB"
                            
                            notify_text = f"ğŸ“ å¤åˆ¶+æ”¹Hash | ğŸ’¾ {size_str}"
                            
                            self.post_message(
                                mtype=NotificationType.Manual,
                                title=f"âœ… è½¬ç§»ï¼š{new_file_path.name}",
                                text=notify_text
                            )
                            logger.info(f"copyhashæ¨¡å¼ï¼šå·²å‘é€ç®€åŒ–é€šçŸ¥")
                        
                        # æ·»åŠ åˆ°æ‰¹æ¬¡æ±‡æ€»
                        original_dir = relative_path.parent if relative_path.parent != Path('.') else "æ ¹ç›®å½•"
                        target_relative = new_file_path.relative_to(target)
                        target_dir_display = target_relative.parent if target_relative.parent != Path('.') else "æ ¹ç›®å½•"
                        
                        self.__add_to_batch({
                            'time': datetime.now(),
                            'source_dir': str(original_dir),
                            'target_dir': str(target_dir_display),
                            'source_file': file_path.name,
                            'target_file': new_file_path.name,
                            'size': new_size,
                            'method': 'copyhash'
                        })
                        
                        logger.info(f"copyhashæ¨¡å¼ï¼š{file_path.name} å¤„ç†æˆåŠŸ")
                        return
                    except Exception as e:
                        logger.error(f"copyhashæ¨¡å¼å¤„ç†å¤±è´¥ï¼š{str(e)}")
                        logger.error(f"copyhashæ¨¡å¼ï¼šé”™è¯¯è¯¦æƒ… {traceback.format_exc()}")
                        return
                
                else:
                    # ä¸æ”¯æŒçš„è½¬ç§»æ–¹å¼
                    logger.error(f"ä¸æ”¯æŒçš„è½¬ç§»æ–¹å¼ï¼š{transfer_type}ï¼Œä»…æ”¯æŒlinkå’Œcopyhash")
                    return
        
        except Exception as e:
            logger.error("ç›®å½•ç›‘æ§å‘ç”Ÿé”™è¯¯ï¼š%s - %s" % (str(e), traceback.format_exc()))


    def get_state(self) -> bool:
        return self._enabled

    @staticmethod
    def get_command() -> List[Dict[str, Any]]:
        """
        å®šä¹‰è¿œç¨‹æ§åˆ¶å‘½ä»¤
        :return: å‘½ä»¤å…³é”®å­—ã€äº‹ä»¶ã€æè¿°ã€é™„å¸¦æ•°æ®
        """
        return [{
            "cmd": "/cloud_link_sync",
            "event": EventType.PluginAction,
            "desc": "äº‘ç›˜å®æ—¶ç›‘æ§åŒæ­¥",
            "category": "",
            "data": {
                "action": "cloud_link_sync"
            }
        }]

    def get_api(self) -> List[Dict[str, Any]]:
        return [{
            "path": "/cloud_link_sync",
            "endpoint": self.sync,
            "methods": ["GET"],
            "summary": "äº‘ç›˜å®æ—¶ç›‘æ§åŒæ­¥",
            "description": "äº‘ç›˜å®æ—¶ç›‘æ§åŒæ­¥",
        }]

    def get_service(self) -> List[Dict[str, Any]]:
        """
        æ³¨å†Œæ’ä»¶å…¬å…±æœåŠ¡
        [{
            "id": "æœåŠ¡ID",
            "name": "æœåŠ¡åç§°",
            "trigger": "è§¦å‘å™¨ï¼šcron/interval/date/CronTrigger.from_crontab()",
            "func": self.xxx,
            "kwargs": {} # å®šæ—¶å™¨å‚æ•°
        }]
        """
        if self._enabled and self._cron:
            return [{
                "id": "CloudLinkMonitor",
                "name": "äº‘ç›˜å®æ—¶ç›‘æ§å…¨é‡åŒæ­¥æœåŠ¡",
                "trigger": CronTrigger.from_crontab(self._cron),
                "func": self.sync_all,
                "kwargs": {}
            }]
        return []

    def sync(self) -> schemas.Response:
        """
        APIè°ƒç”¨ç›®å½•åŒæ­¥
        """
        self.sync_all()
        return schemas.Response(success=True)

    def get_form(self) -> Tuple[List[dict], Dict[str, Any]]:
        return [
            {
                'component': 'VForm',
                'content': [
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'enabled',
                                            'label': 'å¯ç”¨æ’ä»¶',
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'notify',
                                            'label': 'å‘é€é€šçŸ¥',
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSwitch',
                                        'props': {
                                            'model': 'onlyonce',
                                            'label': 'ç«‹å³è¿è¡Œä¸€æ¬¡',
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VSelect',
                                        'props': {
                                            'model': 'transfer_type',
                                            'label': 'è½¬ç§»æ–¹å¼',
                                            'items': [
                                                {'title': 'ç¡¬é“¾æ¥', 'value': 'link'},
                                                {'title': 'å¤åˆ¶æ”¹Hash', 'value': 'copyhash'}
                                            ]
                                        }
                                    }
                                ]
                            },
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                    'md': 4
                                },
                                'content': [
                                    {
                                        'component': 'VTextField',
                                        'props': {
                                            'model': 'cron',
                                            'label': 'å®šæ—¶ä»»åŠ¡',
                                            'placeholder': '0 0 * * *'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12
                                },
                                'content': [
                                    {
                                        'component': 'VTextarea',
                                        'props': {
                                            'model': 'monitor_dirs',
                                            'label': 'ç›‘æ§ç›®å½•',
                                            'rows': 5,
                                            'placeholder': 'æ¯ä¸€è¡Œä¸€ä¸ªç›®å½•ï¼Œæ”¯æŒä»¥ä¸‹å‡ ç§é…ç½®æ–¹å¼ï¼š\n'
                                                           'ç›‘æ§ç›®å½•:è½¬ç§»ç›®çš„ç›®å½•\n'
                                                           'ç›‘æ§ç›®å½•:è½¬ç§»ç›®çš„ç›®å½•#link\n'
                                                           'ç›‘æ§ç›®å½•:è½¬ç§»ç›®çš„ç›®å½•#copyhash\n'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VTextarea',
                                        'props': {
                                            'model': 'exclude_keywords',
                                            'label': 'æ’é™¤å…³é”®è¯',
                                            'rows': 2,
                                            'placeholder': 'æ¯ä¸€è¡Œä¸€ä¸ªå…³é”®è¯'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        'component': 'VRow',
                        'content': [
                            {
                                'component': 'VCol',
                                'props': {
                                    'cols': 12,
                                },
                                'content': [
                                    {
                                        'component': 'VAlert',
                                        'props': {
                                            'type': 'info',
                                            'variant': 'tonal',
                                            'text': 'linkæ¨¡å¼ï¼šç¡¬é“¾æ¥ï¼ˆåŒæ–‡ä»¶ç³»ç»Ÿï¼‰æˆ–å¤åˆ¶ï¼ˆè·¨æ–‡ä»¶ç³»ç»Ÿï¼‰+æ”¹åï¼Œä¸æ”¹hashã€‚\ncopyhashæ¨¡å¼ï¼šå¤åˆ¶+æ”¹å+æ”¹hashã€‚\nä¸¤ç§æ¨¡å¼éƒ½ä¼šæ··æ·†ç›®å½•åï¼ˆä¿ç•™1-2ä¸ªå­—+ç¹ä½“å­—+å¹´ä»½ï¼‰å’Œæ–‡ä»¶åï¼ˆS01E01-1080p.mkvæˆ–1080p.mkvï¼‰ï¼ŒSeasonç›®å½•ä¸æ”¹ã€‚'
                                        }
                                    }
                                ]
                            }
                        ]
                    },
                ]
            }
        ], {
            "enabled": False,
            "notify": False,
            "onlyonce": False,
            "transfer_type": "link",
            "monitor_dirs": "",
            "exclude_keywords": "",
            "cron": "",
            "size": 0
        }

    def get_page(self) -> List[dict]:
        pass

    def stop_service(self):
        """
        é€€å‡ºæ’ä»¶
        """
        if self._observer:
            for observer in self._observer:
                try:
                    observer.stop()
                    observer.join()
                except Exception as e:
                    print(str(e))
        self._observer = []
        if self._scheduler:
            self._scheduler.remove_all_jobs()
            if self._scheduler.running:
                self._event.set()
                self._scheduler.shutdown()
                self._event.clear()
            self._scheduler = None
